* linux 下复制文件时显示进度

    `pv`（Pipe Viewer）可以显示复制进度、速度和估计时间。

    安装：`sudo apt install pv`

    * 复制单个文件
    
        `pv source_file > destination_file`

    * 复制整个目录

        `tar cf - source_dir | pv | tar xf - -C destination_dir`

    可以创建一个带进度复制的脚本：

    `/usr/local/bin/cpv`:

    ```bash
    #!/bin/bash
    tar cf - "$1" | pv | tar xf - -C "$2"
    ```

* `rsync -h`

    -h 参数表示 "human-readable"（人类可读格式）。自动将字节转换为 KB、MB、GB、TB 等单位, 使输出更加友好和直观。

    其他常用 rsync 参数说明：

    * `-a` (archive)：归档模式，相当于 -rlptgoD

        * `-r`：递归复制目录

        * `-l`：保留符号链接

        * `-p`：保留权限

        * `-t`：保留修改时间

        * `-g`：保留属组

        * `-o`：保留属主

        * `-D`：保留设备文件

    * `--progress`：显示传输进度

    * `-v`：详细输出（显示正在复制的文件）

    * `-z`：压缩传输数据

    * `--delete`：删除目标中源不存在的文件

    常用组合：

    ```bash
    # 基本复制（推荐）
    rsync -ah --progress source destination

    # 详细输出 + 压缩
    rsync -azh --progress source destination

    # 同步（删除目标中多余的文件）
    rsync -ah --progress --delete source destination

    # 远程复制
    rsync -azh --progress /local/path/ user@remote:/remote/path/
    ```

* `torch.nn.Module`

    * `__init__()`: The __init__ method is used to initialize the module's parameters. This method is called when the module is created, and it allows we to set up any internal state that the module needs. For example, we might use this method to initialize the weights of a neural network or to create other modules that the module needs in order to function.

    * `forward()`: The forward method is used to perform the computation that the module represents. This method takes in one or more input tensors, performs computations on them, and returns the output tensors. It is a forward pass of the module.

    example:

    ```py
    class MyModule(nn.Module):
        
        # Initialize the parameter
        def __init__(self, num_inputs, num_outputs, hidden_size):
            super(MyModule, self).__init__()
            self.linear1 = nn.Linear(num_inputs, hidden_size)
            self.linear2 = nn.Linear(hidden_size, num_outputs)
        
        # Forward pass
        def forward(self, input):
            lin    = self.linear1(input)
            output = nn.functional.relu(lin)
            pred   = self.linear2(output)
            return pred

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(my_module.parameters(), lr=0.005)

    transform = transforms.Compose([transforms.ToTensor(), 
                                    transforms.Normalize((0.5,), (0.5,))])
    ```

    complete code:

    ```py
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torchvision import datasets, transforms
    from sklearn.metrics import classification_report

    class MyModule(nn.Module):
        def __init__(self, num_inputs, num_outputs, hidden_size):
            super(MyModule, self).__init__()
            self.linear1 = nn.Linear(num_inputs, hidden_size)
            self.linear2 = nn.Linear(hidden_size, num_outputs)

        def forward(self, input):
            lin    = self.linear1(input)
            output = nn.functional.relu(lin)
            pred   = self.linear2(output)
            return pred

    # Instantiate the custom module
    my_module = MyModule(num_inputs=28*28, num_outputs=10, hidden_size=20)

    # Define the loss function and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(my_module.parameters(), lr=0.01)

    # Define the transformations for the dataset
    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

    # Load the MNIST dataset
    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

    # Define the data loader
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)

    # Train the model
    for epoch in range(10):
        for i, (images, labels) in enumerate(train_loader):
            images = images.view(-1, 28*28)
            optimizer.zero_grad()
            output = my_module(images)
            loss = criterion(output, labels)
            loss.backward()
            optimizer.step()
        print('Epoch -->',epoch,'-->',loss)

        

    #Test the model
    with torch.no_grad():
        y_true = []
        y_pred = []
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.view(-1, 28*28)
            output = my_module(images)
            _, predicted = torch.max(output.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum()
            y_true += labels.tolist()
            y_pred += predicted.tolist()

        # Accuracy
        print('Accuracy: {} %'.format(100 * correct / total))
        
        # Classification Report
        report = classification_report(y_true, y_pred)
        print(report)
    ```

* `__attribute__((packed))`

    这个主要用于取消结构体对齐。

    ```c
    // 正常情况（假设 4 字节对齐）
    struct normal {
        char a;      // 1 字节
        int b;       // 4 字节
        char c;      // 1 字节
    };
    // sizeof(struct normal) = 12 字节（有填充）

    // 使用 packed
    struct __attribute__((packed)) packed_struct {
        char a;      // 1 字节
        int b;       // 4 字节
        char c;      // 1 字节
    };
    // sizeof(struct packed_struct) = 6 字节（无填充）
    ```

    主要用途:

    1. 硬件/协议数据映射
    
        ```c
        // 网络协议头
        struct __attribute__((packed)) eth_header {
            uint8_t dst_mac[6];
            uint8_t src_mac[6];
            uint16_t eth_type;
        };
        ```

    2. 节省内存空间

        在内存受限的嵌入式系统中减少内存占用。

    3. 数据序列化

        确保结构体布局与外部数据格式完全匹配。

    其他替代方案：

    1. 手动序列化（推荐）

        ```c
        void serialize_eth_header(const struct eth_header *hdr, uint8_t *buffer) {
            memcpy(buffer, hdr->dst_mac, 6);
            memcpy(buffer + 6, hdr->src_mac, 6);
            memcpy(buffer + 12, &hdr->eth_type, 2);
        }
        ```

    2. 使用编译器对齐指令

        ```c
        // 指定最小对齐而非完全取消
        struct __attribute__((aligned(1))) minimal_align {
            // ...
        };
        ```