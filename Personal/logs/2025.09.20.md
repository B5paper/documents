* `free_irq()`

    free an interrupt allocated with request_irq

    syntax:

    ```c
    void free_irq(unsigned int irq, void * dev_id);
    ```

* `request_irq()` example

    ```c
    #include <linux/init.h>
    #include <linux/module.h>
    #include <linux/pci.h>

    static struct pci_device_id pci_id_table[] = {
        { PCI_DEVICE(0x1234, 0x11e8) },
        {0,}
    };

    static void *base_addr_bar0;
    static struct pci_dev *hlc_pci_dev = NULL;

    irqreturn_t irq_handler(int irq, void *dev_id) {
        pr_info("in irq_handler()...\n");
        if (dev_id != hlc_pci_dev) {
            pr_warn("dev_id != hlc_pci_dev\n");
            return IRQ_NONE;
        }

        return IRQ_HANDLED;
    }

    static int edu_probe(struct pci_dev *pci_dev, const struct pci_device_id *id) {
        pr_info("in edu_probe()...\n");
        hlc_pci_dev = pci_dev;
        
        int ret = pci_enable_device(pci_dev);
        if (ret != 0) {
            dev_err(&pci_dev->dev, "fail to pci enable device, ret: %d\n", ret);
            goto ERR_PCI_ENABLE_DEVICE;
        }

        // mmio
        ret = pci_request_region(pci_dev, 0, "qemu_edu_drv");
        if (ret != 0) {
            dev_err(&pci_dev->dev, "fail to pci request region\n");
            goto ERR_PCI_REQUEST_REGION;
        }

        resource_size_t res_len_bar0 = pci_resource_len(pci_dev, 0);
        base_addr_bar0 = pci_iomap(pci_dev, 0, res_len_bar0);
        if (base_addr_bar0 == NULL) {
            dev_err(&pci_dev->dev, "fail to pci iomap\n");
            goto ERR_PCI_IOMAP;
        }

        // dma
        ret = dma_set_mask_and_coherent(&pci_dev->dev, DMA_BIT_MASK(28));
        if (ret != 0) {
            dev_err(&pci_dev->dev, "fail to set dma mask and conherent\n");
            goto ERR_DMA_SET_MASK_AND_COHERENT;
        }

        // irq
        ret = request_irq(pci_dev->irq, irq_handler, IRQF_SHARED, "qemu_edu_dev_irq_handler", pci_dev);
        if (ret != 0) {
            dev_err(&pci_dev->dev, "fail to request irq\n");
            goto ERR_REQUEST_IRQ;
        }

        pr_info("successfully probe edu pci dev\n");

        return 0;

    ERR_REQUEST_IRQ:
    ERR_DMA_SET_MASK_AND_COHERENT:
        pci_iounmap(pci_dev, base_addr_bar0);
    ERR_PCI_IOMAP:
        pci_release_region(pci_dev, 0);
    ERR_PCI_REQUEST_REGION:
        pci_disable_device(pci_dev);
    ERR_PCI_ENABLE_DEVICE:
        return -1;
    }

    static void edu_remove(struct pci_dev *pci_dev) {
        pr_info("in edu_remove()...\n");
        free_irq(pci_dev->irq, pci_dev);
        pci_iounmap(pci_dev, base_addr_bar0);
        pci_release_region(pci_dev, 0);
        pci_disable_device(pci_dev);
    }

    static struct pci_driver edu_driver = {
        .name = "qemu_edu_drv",
        .id_table = pci_id_table,
        .probe = edu_probe,
        .remove = edu_remove
    };

    int init_mod(void) {
        pr_info("init hlc module...\n");
        int ret = pci_register_driver(&edu_driver);
        if (ret != 0) {
            pr_err("fail to register pci driver\n");
            goto ERR_PCI_REGISTER_DRIVER;
        }
        return 0;

    ERR_PCI_REGISTER_DRIVER:
        return -1;
    }

    void exit_mod(void) {
        pr_info("exit hlc module...\n");
        pci_unregister_driver(&edu_driver);
    }

    module_init(init_mod);
    module_exit(exit_mod);
    MODULE_LICENSE("GPL");
    ```

    dmesg output:

    ```
    [ 3040.252553] hello: loading out-of-tree module taints kernel.
    [ 3040.252692] hello: module verification failed: signature and/or required key missing - tainting kernel
    [ 3040.256257] init hlc module...
    [ 3040.256842] in edu_probe()...
    [ 3040.292191] ACPI: \_SB_.LNKD: Enabled at IRQ 10
    [ 3040.292492] successfully probe edu pci dev
    [ 3051.406874] exit hlc module...
    [ 3051.406976] in edu_remove()...
    ```

* 很多比较大的概念可以被分解成小的概念，每个小概念占一个 entry，但是 routine 相关的知识点几乎无法被分解，它描述小 entry 如何被串起来完成一件大任务。

    典型的场景，比如 vulkan 如何沉浸一帧图片。

* 仅靠堆叠小概念 entry，无法推导出如何组合成一个复杂任务，学习的过程也很慢。

    堆叠小概念的过程是线性过程，所有的新概念都是从原有概念延伸而来，对于新概念，还可以进行发散、联想和探索，但是无法更近一步，快速地把 micro concept entry 串起来组成一个复杂任务，或者一个具有完整功能的任务。

    串起复杂任务的过程，必须依靠 example 和非线性学习，充满了猜想、假设、和大脑必须保存的 routine 上下文缓存。 

* 笔记应该有两种形式，一种是从 micro concept entry 出发，解释概念，并给出忽略上下文的、简短的 example；另一种是从 example / routine 出发，在 example 下方给出说明，一条一条地批注、解释。

    其中，micro concept entry 的发展路径可以为：micro concept entry -> topic -> typical example (on top)

    这样一来，micro concept entry 的方式是自底向上，example / routine 的方式是自顶向下，这种方式结合才能理解一套复杂系统，我们不可以脱离一边只使用另外一边。

* 使用`move()`移动 vector，其实移动的是 vector 内部的 buffer 指针

    ```cpp
    #include <vector>
    #include <stdio.h>
    #include <utility>
    using namespace std;

    int main() {
        vector<int> vec_a{1, 2, 3, 4, 5, 6};
        vector<int> vec_b;

        printf("%p\n", vec_a.data());
        vec_b = move(vec_a);
        printf("%p\n", vec_a.data());
        printf("%p\n", vec_b.data());

        printf("%d\n", vec_a[0]);
        printf("%d\n", vec_b[5]);
        return 0;
    }
    ```

    output:

    ```
    0x64b2694f5eb0
    (nil)
    0x64b2694f5eb0
    Segmentation fault (core dumped)
    ```

    可以看到，经过 move 后，`vec_b`的 buffer addr 变成了之前`vec_a`的。`vec_a`的 buffer 指针则被置空，当再次访问时会报错。

* makefile 中的变量与 shell 变量

    ```makefile
    makefile_var := hello, makefile

    test:
    	@echo $(makefile_var)
    	@bash_var="hello, bash"; \
    	echo $${bash_var}
    ```

    `make` output:

    ```
    hello, makefile
    hello, bash
    ```

    `$()`可以引用到前面定义的 makefile 变量。

    makefile target 中的每行都是一个独立 bash 环境，如果需要定义 bash 变量，那么可以使用`; \`将多行 bash 命令看作一行，或者直接写成一行的形式。

    调用 bash 变量时，必须使用两个美元符号`$$`，比如`$$shell_var`, `$${shell_var}`。make 会将两个美元符号变成一个，然后传给 shell。

    说明：

    1. shell 变量不可以使用圆括号`$$()`

    1. shell 写成两行是不可以的，因为算作两个独立的 bash 环境

        ```makefile
        target:
        	@bash_var="hello, bash"
        	@echo $${bash_var}
        ```

        输出为空。

    * Make 变量 在规则的目标、依赖和整个 Makefile 的顶层使用 $(...) 来引用。

    * Shell 变量 在规则的命令部分（以 Tab 开头的行）中使用，但需要使用两个美元符号 $$ 来转义。

* makefile 中可以使用`$(shell )`帮助实现 bash 中拼接字符串的效果

    example:

    ```makefile
    var_1 := hello, $(uname -r)
    var_2 := hello, $(shell uname -r)

    test:
    	@echo ${var_1}
    	@echo $(var_2)
    ```

    output:

    ```
    hello,
    hello, 6.8.0-79-generic
    ```

* `std::make_unique()`

    在动态内存中构造一个指定类型的对象，并返回一个管理该对象的 unique_ptr。

    C++14 引入, 最推荐的创建 std::unique_ptr 的方式。

    example:

    ```cpp
    #include <memory>

    class MyClass {
    public:
        MyClass(int a, double b) {}
        void doSomething() {}
    };

    int main() {
        // 创建单个对象
        auto ptr1 = std::make_unique<MyClass>(42, 3.14);
        ptr1->doSomething();

        // 创建数组 (C++14 起，但更推荐对数组使用 std::vector)
        auto ptr2 = std::make_unique<int[]>(10); // 10 个整数的动态数组
        ptr2[0] = 1;

        return 0;
    }
    ```


    优点：

    1. 异常安全：防止因异常导致的内存泄漏。如果在一个复杂表达式中分配内存，make_unique 能确保在发生异常时已分配的内存会被正确释放。

    2. 代码简洁：无需重复书写类型（使用 auto 时），只需要指定一次类型和构造函数参数即可。

    3. 性能：make_unique 有机会优化内存分配的开销。

* 常见的构造 std::unique_ptr 的方法

    * 使用裸指针构造函数

        用一个已存在的裸指针来构造 unique_ptr，unique_ptr 将接管该指针的所有权。

        example:

        ```cpp
        // 不推荐！仅作演示
        MyClass* raw_ptr = new MyClass(10, 5.5);
        std::unique_ptr<MyClass> ptr(raw_ptr); // ptr 现在接管 raw_ptr
        // 切记：此后绝不能再使用或删除 raw_ptr
        ```

        注意：

        1. 极度危险：必须确保这个裸指针是刚通过 new 分配出来的，并且没有被其他任何 unique_ptr 或 shared_ptr 管理。否则会导致重复释放等未定义行为。

        2. 应该尽量避免使用这种方法，优先选择 make_unique。

    * 使用 std::move() 进行所有权转移

        unique_ptr 是不可拷贝的，但可以移动。这意味着你可以将一个 unique_ptr 的所有权转移给另一个 unique_ptr。

        example:

        ```cpp
        auto source_ptr = std::make_unique<MyClass>(1, 2.0);
        // std::move 将 source_ptr 从“左值”变为“右值”，从而触发移动构造函数
        std::unique_ptr<MyClass> destination_ptr = std::move(source_ptr);

        // 移动后，source_ptr 变为 nullptr，不再拥有任何资源
        // destination_ptr 现在拥有之前 source_ptr 管理的对象
        ```

* unique_ptr 自定义删除器 (Custom Deleter)

    默认情况下，unique_ptr 使用 delete 或 delete[] 来释放资源。你可以指定一个自定义的删除器函数或函数对象，用于释放特殊资源（如文件句柄 (fclose)、套接字、特定 API 分配的内存等）。

    example:

    ```cpp
    #include <iostream>
    #include <memory>

    // 一个自定义的删除器，模拟用于需要特殊清理的资源
    struct FileDeleter {
        void operator()(std::FILE* file_ptr) const {
            if (file_ptr) {
                std::fclose(file_ptr);
                std::cout << "File closed using custom deleter.\n";
            }
        }
    };

    int main() {
        // 使用自定义删除器打开文件
        // 注意：这里必须使用裸指针构造函数，因为 make_unique 不支持自定义删除器
        std::unique_ptr<std::FILE, FileDeleter> file_ptr(
            std::fopen("data.txt", "r"), 
            FileDeleter()
        );

        if (file_ptr) {
            // 使用 file_ptr.get() 获取裸指针来操作文件
            std::cout << "File opened successfully.\n";
        }
        // 当 file_ptr 离开作用域时，FileDeleter 会被调用，自动关闭文件
        return 0;
    }
    ```

    注意：使用自定义删除器会改变 unique_ptr 的类型，std::unique_ptr<T, Deleter> 与默认的 std::unique_ptr<T> 是不同的类型。

* unique_ptr 的释放和重置

    release()：放弃对指针的控制权，返回裸指针，并将 unique_ptr 自身置为 nullptr。调用者负责管理返回的裸指针的生命周期。

    reset()：销毁当前管理的对象（如果存在），然后接管一个新提供的裸指针（如果提供了的话），或者直接置为 nullptr。

    example:

    ```cpp
    auto ptr = std::make_unique<int>(100);

    // release() 示例
    int* released_ptr = ptr.release(); // ptr 现在是空的
    // 必须手动删除 released_ptr: delete released_ptr;

    // reset() 示例
    ptr.reset(new int(200)); // 先删除旧的 100，然后管理新的 200
    ptr.reset();             // 删除 200，ptr 变为 nullptr
    ```

* `posix_memalign()`

    一个 POSIX 标准函数, 动态分配一块内存，并保证这块内存的起始地址是对齐在某个特定字节边界上的。

    syntax:

    ```c
    #include <stdlib.h>

    int posix_memalign(void **memptr, size_t alignment, size_t size);
    ```

    params:

    * `size_t alignment`

        指定所需的内存对齐边界，单位是字节。

        这个值必须是 2 的幂次方（如 1, 2, 4, 8, 16, 32, 64, ...），并且必须是 sizeof(void *) 的整数倍。

        常见的值：16 (SSE), 32 (AVX), 64 (AVX-512, 缓存行对齐)。

    * `size_t size`

        指定需要分配的内存块大小，单位是字节。

        注意：分配的内存大小不需要是 alignment 的倍数，但通常你会分配对齐大小的整数倍以确保充分利用。

    返回值：

    * 成功时，返回 0。

    * 失败时，返回一个错误码（不是设置 errno）。常见的错误码有：

        * EINVAL: 参数无效。通常是 alignment 不是 2 的幂次方，或者不是 sizeof(void *) 的倍数。

        * ENOMEM: 内存不足，无法完成分配请求。

    与 aligned_alloc() 的关系：posix_memalign() 是 POSIX 的扩展，而 aligned_alloc() 是 C11 标准引入的函数。两者功能类似，但在参数细节上略有不同。在支持 C11 的环境下，aligned_alloc() 是更可移植的标准选择。

* python 中的 f-string

    f"xxx" 是 f-string（格式化字符串字面值，Formatted string literals）的语法，它在 Python 3.6 中首次引入。它是一种在字符串中直接嵌入表达式的字符串格式化机制.

    基本用法:

    * 嵌入变量（最基本的功能）

        在字符串前加上前缀 f 或 F，然后在字符串内部用大括号 {} 包裹变量名或表达式。Python 会在运行时计算 {} 中的内容，并将其值转换为字符串插入到相应位置。

        example:

        ```py
        name = "Alice"
        age = 30

        # 传统的格式化方法
        greeting_old = "Hello, {}. You are {} years old.".format(name, age)
        # 使用 f-string
        greeting_new = f"Hello, {name}. You are {age} years old."

        print(greeting_new)
        # 输出: Hello, Alice. You are 30 years old.
        ```

    * 执行表达式

        {} 内不仅可以放变量，还可以放任何有效的 Python 表达式。

        example:

        ```py
        a = 5
        b = 10

        result = f"The sum of {a} and {b} is {a + b}, and their product is {a * b}."
        print(result)
        # 输出: The sum of 5 and 10 is 15, and their product is 50.
        ```

    * 调用函数和方法

        可以在 {} 中直接调用函数或对象的方法。

        example:

        ```py
        name = "bob"
        message = f"Your name in uppercase is {name.upper()} and its length is {len(name)}."
        print(message)
        # 输出: Your name in uppercase is BOB and its length is 3.
        ```

    * 格式化输出（类似 str.format() 的格式规范）

        可以在表达式后面跟上格式说明符（format specifier），用来控制输出的格式，比如小数点精度、数字的进制、对齐方式等。语法是 `{expression:format_spec}`。

        example:

        ```py
        import math

        price = 19.9876
        number = 42

        # 控制浮点数精度（保留两位小数）
        f_price = f"The price is ${price:.2f}" # 输出: The price is $19.99

        # 格式化为十六进制
        f_hex = f"The number {number} in hex is {number:#x}" # 输出: The number 42 in hex is 0x2a

        # 百分比显示
        f_percent = f"Completion: {0.756:.2%}" # 输出: Completion: 75.60%

        # 对齐文本（:>10 表示右对齐，宽度为10个字符）
        f_align = f"'{name:>10}'" # 输出: '       bob'

        print(f_price)
        print(f_hex)
        print(f_percent)
        print(f_align)
        ```

    * 转义大括号

        如果需要在 f-string 中显示字面意义的大括号，需要使用双重大括号进行转义。

        example:

        ```py
        value = "data"
        escaped = f"This is how you show braces: {{{value}}}" # 注意三层括号
        print(escaped)
        # 输出: This is how you show braces: {data}
        ```

    注意事项:

    * 引号问题：f-string 可以使用单引号 `'`、双引号 `"` 和三引号 `'''/"""`。

        ```py
        f'Hello, {name}.'
        f"Hello, {name}."
        f"""Hello,
        {name}."""
        ```

    * 表达式求值：f-string 中的表达式在运行时求值。这意味着它们使用的是当前作用域中的变量值。

    * 不能为空：{} 内部不能是空的，必须包含表达式。

    * Python 版本：确保你的运行环境是 Python 3.6 或更高版本，否则会引发 SyntaxError。

* `tens.index_copy_()`

    将指定维度上的指定索引（可以是多个）复制到`tens`的对应位置。

    syntax:

    ```py
    index_copy_(dim, index, tensor) -> Tensor
    ```

    example:

    ```py
    import torch

    tens_1 = torch.ones(4, 4)
    tens_2 = torch.randn(2, 4)
    my_indices = torch.tensor([1,3])

    tens_1.index_copy_(0, my_indices, tens_2)
    print("tens_1: {}".format(tens_1))
    ```

    output:

    ```
    tens_1: tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],
            [ 0.3654,  0.9840, -0.4651,  1.4270],
            [ 1.0000,  1.0000,  1.0000,  1.0000],
            [ 0.0722, -1.2526, -0.8574, -1.2249]])
    ```

    注意：

    * `my_indices`元素的数量必须和`tens_2`在`dim`维度上的长度对应，即`my_indices.size() == tens_2.shape[dim]`。上面例子中，如果`tens_2 = torch.randn(3, 4)`，则会报错。

    `index_copy()`是其 out-of-place 版本。

* `scipy.sparse.csr_matrix`

    Compressed Sparse Row matrix

    是 SciPy 库中用于表示稀疏矩阵的一种数据结构。它专门用于高效地存储和操作那些大部分元素为零的矩阵。

    CSR 格式只存储非零元素的值及其位置，极大地节省了内存和计算时间。

    适用场景:

    * 词袋模型（Bag-of-Words）中的文档-词项矩阵

    * 图的邻接矩阵

    * 有限元分析中的刚度矩阵

    CSR 格式通过三个一维数组来表示整个矩阵：

    1. data：存储所有非零元素的值。

    2. indices：存储每个非零元素所在的列索引。

    3. indptr（索引指针）：存储每一行第一个非零元素在 data 和 indices 中的起始位置。

    这种结构使得按行访问和操作（如矩阵-向量乘法）非常高效。

* `csr_matrix`的创建方法

    * 从密集矩阵（Dense Array）创建

        从一个普通的 2D NumPy 数组或列表的列表创建。

        ```py
        import numpy as np
        from scipy.sparse import csr_matrix

        dense_matrix = np.array([[1, 0, 0, 0],
                                 [0, 0, 2, 0],
                                 [0, 3, 0, 4]])
                                 
        sparse_matrix = csr_matrix(dense_matrix)
        print(sparse_matrix)
        print(sparse_matrix.toarray()) # 转回密集矩阵查看
        ```

        output:

        ```
        <Compressed Sparse Row sparse matrix of dtype 'int64'
        	with 4 stored elements and shape (3, 4)>
          Coords	Values
          (0, 0)	1
          (1, 2)	2
          (2, 1)	3
          (2, 3)	4
        [[1 0 0 0]
         [0 0 2 0]
         [0 3 0 4]]
        ```

    * 使用 (data, (row, col)) 坐标格式创建

        明确指定每个非零元素的值及其所在的行和列坐标

        ```py
        import numpy as np
        from scipy.sparse import csr_matrix

        # 数据： [1, 2, 3, 4]
        # 行索引：[0, 1, 2, 2] -> 第一个元素在第0行，第二个在第1行，第三、四个在第2行
        # 列索引：[0, 2, 1, 3] -> 第一个元素在第0列，第二个在第2列，第三个在第1列，第四个在第3列

        data = [1, 2, 3, 4]
        row = [0, 1, 2, 2]
        col = [0, 2, 1, 3]

        sparse_matrix = csr_matrix((data, (row, col)), shape=(3, 4))
        print(sparse_matrix.toarray())
        ```

        output:

        ```
        [[1 0 0 0]
         [0 0 2 0]
         [0 3 0 4]]
        ```

    * 使用 (data, indices, indptr) 直接创建（高级）

        直接使用 CSR 格式的三个内部数组来创建。

        ```py
        # 假设矩阵为：
        # [[1, 0, 2, 0]
        #  [0, 0, 3, 4]
        #  [5, 0, 0, 6]]

        data = [1, 2, 3, 4, 5, 6]    # 所有非零值
        indices = [0, 2, 2, 3, 0, 3] # 每个值对应的列号
        indptr = [0, 2, 4, 6]        # 第i行的非零值范围是 data[indptr[i]:indptr[i+1]]

        # indptr 解释：
        # 第0行：有 indptr[1]-indptr[0] = 2 个元素，是 data[0:2] -> [1,2]，列号为 indices[0:2] -> [0,2]
        # 第1行：有 indptr[2]-indptr[1] = 2 个元素，是 data[2:4] -> [3,4]，列号为 indices[2:4] -> [2,3]
        # 第2行：有 indptr[3]-indptr[2] = 2 个元素，是 data[4:6] -> [5,6]，列号为 indices[4:6] -> [0,3]

        sparse_matrix = csr_matrix((data, indices, indptr), shape=(3, 4))
        print(sparse_matrix.toarray())
        # [[1 0 2 0]
        #  [0 0 3 4]
        #  [5 0 0 6]]
        ```

* `csc_matrix`常用属性和操作

    * 查看矩阵信息

        ```py
        print(sparse_matrix.shape)   # 矩阵形状: (3, 4)
        print(sparse_matrix.nnz)     # 非零元素个数: 4
        print(sparse_matrix.dtype)   # 数据类型: int64
        print(sparse_matrix.has_sorted_indices) # 索引是否已排序: True
        ```

    * 转换格式

        ```py
        # 转换为其他稀疏格式
        csc_matrix = sparse_matrix.tocsc() # 转为CSC格式（按列压缩，列操作快）
        coo_matrix = sparse_matrix.tocoo() # 转为COO格式（坐标格式，构建快）

        # 转换为密集NumPy数组
        dense_array = sparse_matrix.toarray()
        ```

    * 数学运算

        ```py
        # 标量运算
        result = sparse_matrix * 2   # 所有非零元素乘以2

        # 矩阵运算（结果通常也是稀疏矩阵）
        vector = np.array([1, 2, 3, 4])
        result_vector = sparse_matrix.dot(vector) # 矩阵-向量乘法

        other_sparse_matrix = csr_matrix([[1], [0], [1], [0]])
        result_matrix = sparse_matrix.dot(other_sparse_matrix) # 矩阵-矩阵乘法
        ```

        csr_matrix 支持大多数常见的矩阵运算。

    * 切片和索引

        ```py
        # 获取第1行（返回一个1xN的CSR矩阵）
        row_1 = sparse_matrix[1, :]

        # 获取第2列（效率较低，考虑用CSC格式做列操作）
        col_2 = sparse_matrix[:, 2]
        ```

        对 CSR 矩阵进行切片通常不如对密集矩阵高效，尤其是列切片。

* hugging face 中的数据集

    <https://huggingface.co/datasets>

    使用 python 代码查询：

    ```py
    from huggingface_hub import list_datasets

    # 这是一个生成器，要获取总数需要将其转换为列表，但对于数万个数据集这会很慢且耗内存。
    # all_datasets = list(list_datasets())
    # print(f"Total datasets: {len(all_datasets)}")

    # 更高效的方法是使用分页并计数（但依然需要遍历所有数据集）
    count = 0
    for ds in list_datasets():
        count += 1
    print(f"Total datasets: {count}") # 注意：这会运行一段时间，因为要遍历数万个数据集
    ```

    常见的NLP任务和相关数据集:

    * 文本分类（如情感分析、主题分类）：imdb, ag_news, yelp_review_full

    * 问答（Question Answering）：squad, natural_questions

    * 文本摘要（Summarization）：cnn_dailymail, xsum

    * 文本生成（Text Generation）：wikitext-2, story_cloze

    * 机器翻译（Translation）：wmt14, wmt16, opus_books

    * 命名实体识别（Named Entity Recognition, NER）：conll2003, wnut_17

    * 语义相似度（Semantic Textual Similarity）：stsb_multi_mt

    * 自然语言推理（Natural Language Inference）：mnli, snli

    * 指令微调数据集（用于训练Chat模型）：alpaca, dolly-15k

    使用代码按标签筛选:

    ```py
    from huggingface_hub import list_datasets

    # 查找所有打上 "text-classification" 标签的数据集
    nlp_datasets = list(list_datasets(filter="task_categories:text-classification"))
    print(f"Number of text-classification datasets: {len(list(nlp_datasets))}")

    # 您可以尝试其他标签，如 "text-generation", "question-answering", "translation" 等。
    ```

* `objdump -p <文件名> | grep NEEDED`

    -p 选项：代表显示文件头信息。

* nccl 中用到 topo id 的地方汇总

    * `ncclTopoGetXmlFromChannel()`

        其中有：

        ```cpp
          if (system->nodes[GPU].nodes[i].gpu.rank == intra[g]) {
            int systemId = NCCL_TOPO_ID_SYSTEM_ID(system->nodes[GPU].nodes[i].id);
            dev = NCCL_TOPO_ID(systemId, system->nodes[GPU].nodes[i].gpu.dev);
          }
        ```

    * `ncclTopoPrintGraph()`

        ```cpp
        if (system->nodes[NET].count > 0) {
          sprintf(line+offset, " %s/%lx-%lx", topoNodeTypeStr[NET], NCCL_TOPO_ID_SYSTEM_ID(graph->inter[2*c]), NCCL_TOPO_ID_LOCAL_ID(graph->inter[2*c]));
          offset = strlen(line);
        }
        ```

        ```cpp
        if (system->nodes[NET].count > 0) {
          sprintf(line+offset, " %s/%lx-%lx", topoNodeTypeStr[NET], NCCL_TOPO_ID_SYSTEM_ID(graph->inter[2*c+1]), NCCL_TOPO_ID_LOCAL_ID(graph->inter[2*c+1]));
          offset = strlen(line);
        }
        ```

    * `ncclTopoGetChannelFromXml()`

        ```cpp
          for (int g=0; g<ngpus; g++) {
            int systemId = NCCL_TOPO_ID_SYSTEM_ID(system->nodes[GPU].nodes[g].id);
            if (NCCL_TOPO_ID(systemId, system->nodes[GPU].nodes[g].gpu.dev) == dev) rank = system->nodes[GPU].nodes[g].gpu.rank;
          }
        ```

    * `printNodePaths()`

    * `ncclTopoComputePaths()`

    * `ncclTopoConnectCpus()`

    * `ncclTopoPrintRec()`

    * `ncclTopoDevToRank()`

* 可能对眼睛有益的保健品

    1. 叶黄素和玉米黄质

        作用：这是存在于视网膜黄斑区的两种主要色素，被称为“内在的太阳镜”。它们能有效过滤有害的蓝光，减少氧化损伤，从而帮助缓解畏光和视觉疲劳，同时也是保护黄斑健康的关键。

        食物来源：深绿色蔬菜（菠菜、羽衣甘蓝）、蛋黄、玉米、奇异果。

    2. 花青素（尤其来自越橘和蓝莓）

        作用：强大的抗氧化剂和抗炎剂，可以促进视网膜细胞中的视紫质再生，改善夜间视力、减轻视觉疲劳，对缓解眼干和畏光也有间接好处。

        食物来源：蓝莓、越橘、黑莓、紫甘蓝、黑枸杞。

    3. Omega-3 脂肪酸（尤其是DHA和EPA）

        作用：DHA是视网膜的重要组成部分。Omega-3具有抗炎特性，有助于缓解干眼症（干眼症常常会加重畏光感），并支持视网膜的整体健康。

        食物来源：深海鱼（三文鱼、鲭鱼、沙丁鱼）、亚麻籽、奇亚籽、核桃。

    4. 维生素A / β-胡萝卜素

        作用：维生素A是合成视紫质的关键原料，缺乏它会导致夜盲症和角膜干燥，可能加重畏光。

        食物来源：动物肝脏、胡萝卜、红薯、南瓜。

    5. 锌

        作用：锌是多种酶的重要组成部分，帮助将维生素A从肝脏运送到视网膜以产生黑色素（一种保护性色素）。锌对维持黄斑健康至关重要。

        食物来源：牡蛎、红肉、禽肉、豆类、坚果。

    6. 维生素C和维生素E

        作用：两者都是强大的抗氧化剂，可以保护眼睛细胞免受自由基的损害，延缓眼睛衰老过程。

* vim 中使用文件路径补全

    在插入模式下，输入部分路径后按 Ctrl-x Ctrl-f：

    ```vim
    # 输入 /usr/l 然后按 Ctrl-x Ctrl-f
    cd /usr/l█
    ```

    自动补全菜单

    * `Ctrl` + `n`：向下浏览补全选项

    * `Ctrl` + `p`：向上浏览补全选项

    * `Ctrl` + `y`：确认当前选择的补全项

    * `Ctrl` + `e`：退出补全菜单

* `ipcs -m`

    列出当前系统中所有进程间通信（IPC）的资源中， specifically 关于共享内存（Shared Memory） segments 的详细信息。

    ipcs: 是 “Inter-Process Communication Status” 的缩写，即“进程间通信状态”。这是一个用于报告 IPC 设施状态的工具。

    -m: 指定 ipcs 命令只显示与共享内存（Shared Memory） 相关的信息。如果不加任何选项，ipcs 默认会显示消息队列、共享内存和信号量所有三类信息。

    example:

    ```
    (base) hlc@hlc-VirtualBox:~$ ipcs -m

    ------ Shared Memory Segments --------
    key        shmid      owner      perms      bytes      nattch     status      
    0x00000000 2          hlc        600        524288     2          dest         
    0x00000000 7          hlc        606        7881216    2          dest         
    0x00000000 8          hlc        606        7881216    2          dest         
    0x00000000 34         hlc        600        524288     2          dest         
    0x00000000 32811      hlc        606        7881216    2          dest         
    0x00000000 32812      hlc        606        7881216    2          dest 
    ```

    KEY: 创建共享内存段时指定的键值（key），用于进程间找到同一个内存段。0x00000000 通常是私有用途。

    SHMID: 共享内存段的唯一标识符（ID）。在程序中使用这个 ID 来操作特定的内存段。

    OWNER: 创建该内存段的用户。

    PERMS: 权限位（类似文件权限），如 644 表示所有者可读写，组和其他用户只可读。

    BYTES: 该共享内存段的大小（字节）。

    NATTCH: 当前关联（attach）到这个内存段的进程数量。如果为 0，表示没有进程在使用它，但它可能仍然存在系统中。

    STATUS: 状态信息（在某些系统上可能显示更多细节，如被锁定的内存段）。

* python 中使用实例可以直接定义成员变量

    ```py
    class MyStruc:
        def __init__(self):
            self.val_1 = 123

    obj_1 = MyStruc()
    obj_1.val_2 = 456

    print(obj_1.val_1)
    print(obj_1.val_2)
    ```

    output:

    ```
    123
    456
    ```

    在 IDE 里，`obj_1.`没有关于`val_2`的自动补全和提示，但是运行程序是正常的。

* `nn.MSELoss()`

    Mean Squared Error（均方误差）, 衡量模型预测值 $\hat{y}$ 与真实值 $y$ 之间差的平方的平均值。

    公式：

    $L = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2$

    其中：

    * $L$ 是最终的损失值（一个标量）。

    * $N$ 是样本的数量（或者是需要计算损失的元素的总个数）。

    * $y_i$ 是第 $i$ 个数据的真实值（ground truth）。

    * $\hat{y}_i$ 是模型对第 $i$ 个数据的预测值（prediction）。

    * $\sum_{i=1}^{N}$ 表示对所有 $N$ 个数据点的差值平方进行求和。

    平方的作用：

    * 消除正负误差相互抵消的问题（例如，-2 和 +2 的误差如果直接相加会变成 0，但这显然不对）。

    * 放大较大误差的贡献。误差越大，平方后的惩罚越大，这使得模型会对大的错误更加敏感。

    PyTorch 的 nn.MSELoss 还提供了一个重要的参数 reduction，它可以改变计算最终损失的方式：

    * `reduction='mean'` (默认值): 计算所有元素平方差的平均值。 $\rightarrow L = \frac{1}{N} \sum (y_i - \hat{y}_i)^2$

    * `reduction='sum'`: 计算所有元素平方差的总和。 $\rightarrow L = \sum (y_i - \hat{y}_i)^2$

    * `reduction='none'`: 不进行汇总（sum 或 mean），直接返回一个与输入形状相同的、每个位置都是一个平方差的损失张量。 $\rightarrow L_i = (y_i - \hat{y}_i)^2$

    example:

    ```py
    import torch
    import torch.nn as nn

    # 1. 创建损失函数实例
    # reduction 可以是 'mean', 'sum', 'none'
    criterion = nn.MSELoss() # 默认 reduction='mean'
    # criterion = nn.MSELoss(reduction='sum')
    # criterion = nn.MSELoss(reduction='none')

    # 2. 准备示例数据
    # 假设我们有4个样本的预测值和真实值
    predictions = torch.tensor([3.0, 5.0, 2.5, 4.0])
    targets = torch.tensor([2.5, 4.8, 2.0, 3.8])

    # 3. 计算损失
    loss = criterion(predictions, targets)

    print(f"Predictions: {predictions}")
    print(f"Targets:     {targets}")
    print(f"MSE Loss:    {loss.item()}")
    ```

    output:

    ```
    Predictions: tensor([3.0000, 5.0000, 2.5000, 4.0000])
    Targets:     tensor([2.5000, 4.8000, 2.0000, 3.8000])
    MSE Loss:    0.14499999582767487
    ```

    手动代码实现：

    ```py
    def my_mse_loss(pred, targ, reduction='mean'):
        # 1. 计算所有元素的平方差
        squared_diff = (pred - targ) ** 2
        
        # 2. 根据 reduction 参数进行汇总
        if reduction == 'mean':
            loss = torch.mean(squared_diff)
        elif reduction == 'sum':
            loss = torch.sum(squared_diff)
        elif reduction == 'none':
            loss = squared_diff
        else:
            raise ValueError("reduction must be 'mean', 'sum', or 'none'")
        return loss

    # 使用我们自己实现的函数
    my_loss_mean = my_mse_loss(predictions, targets, 'mean')
    my_loss_sum = my_mse_loss(predictions, targets, 'sum')
    my_loss_none = my_mse_loss(predictions, targets, 'none')

    print(f"Manual MSE Loss (mean): {my_loss_mean.item()}")
    print(f"Manual MSE Loss (sum):  {my_loss_sum.item()}")
    print(f"Manual MSE Loss (none): {my_loss_none}")
    ```

* vim-plug

    official site: <https://github.com/junegunn/vim-plug>

    下载和安装：

    ```bash
    curl -fLo ~/.vim/autoload/plug.vim --create-dirs \
        https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim
    ```

    使用：

    编辑`~/.vimrc`文件：

    ```vim
    call plug#begin()

    " List your plugins here
    Plug 'tpope/vim-sensible'

    call plug#end()
    ```

    进入`vim`，执行命令`:PlugInstall`，此时会开始安装插件`vim-sensible`。若安装成功，则会提示插件`vim-sensible`已经安装成功。此时说明 vim-plug 已经成功安装。

* 内存排序模型（Memory Ordering Models）

    * 顺序一致性（Sequential Consistency, SC）

        最强模型。要求所有线程看到的整个程序的执行顺序是一致的，且每个线程内部的操作顺序就是其程序顺序。几乎在所有指令之间都隐式地插入了全屏障。性能最差，但最容易理解。

    * 宽松内存排序（Relaxed Memory Ordering / Weak Ordering）

        性能最优。允许大量的重排序，除非程序员显式地使用内存屏障指令来约束顺序。

        ARM、PowerPC 等架构是弱内存模型。

    * 介于两者之间（如 x86/x64-64）

        TSO（Total Store Order）模型：这是一种相对较强的模型。

        它只允许一种重排序：后来的读操作可以越过先前的写操作。因此，x86 不需要单独的 LoadLoad 或 LoadStore 屏障，但需要 StoreStore 和（尤其是）StoreLoad 屏障（这是开销最大的一种屏障）来防止这种重排序。