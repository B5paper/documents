* 魔鬼与模仿

* `cudaLaunchKernel()`的 example

    `main.cu`:

    ```cpp
    #include <cuda_runtime.h>
    #include <stdlib.h>
    #include <stdio.h>

    void assign_cubuf_rand_int(float *cubuf, size_t num_elm)
    {
        float *buf = (float*) malloc(num_elm * sizeof(float));
        for (size_t i = 0; i < num_elm; ++i)
        {
            buf[i] = rand() % 5;
        }
        cudaMemcpy(cubuf, buf, num_elm * sizeof(float), cudaMemcpyHostToDevice);
        free(buf);
    }

    void print_cubuf(float *cubuf, size_t num_elm)
    {
        float *buf = (float*) malloc(num_elm * sizeof(float));
        cudaMemcpy(buf, cubuf, num_elm * sizeof(float), cudaMemcpyDeviceToHost);
        for (size_t i = 0; i < num_elm; ++i)
        {
            printf("%.1f, ", buf[i]);
        }
        putchar('\n');
        free(buf);
    }

    __global__ void vec_add(float *A, float *B, float *C)
    {
        int x = threadIdx.x;
        C[x] = A[x] + B[x];
    }

    int main()
    {
        float *cubuf_A, *cubuf_B, *cubuf_C;
        cudaMalloc(&cubuf_A, 8 * sizeof(float));
        cudaMalloc(&cubuf_B, 8 * sizeof(float));
        cudaMalloc(&cubuf_C, 8 * sizeof(float));

        assign_cubuf_rand_int(cubuf_A, 8);
        assign_cubuf_rand_int(cubuf_B, 8);

        puts("cubuf_A:");
        print_cubuf(cubuf_A, 8);
        puts("cubuf_B:");
        print_cubuf(cubuf_B, 8);

        cudaStream_t stream;
        cudaStreamCreate(&stream);

        void *args[3] = {&cubuf_A, &cubuf_B, &cubuf_C};
        // void **args = (void**) malloc(3 * sizeof(void*));
        // args[0] = &cubuf_A;
        // args[1] = &cubuf_B;
        // args[2] = &cubuf_C;
        cudaLaunchKernel((const void *) vec_add, 1, 8, args, 0, stream);
        cudaStreamSynchronize(stream);

        puts("cubuf_C:");
        print_cubuf(cubuf_C, 8);

        cudaFree(cubuf_A);
        cudaFree(cubuf_B);
        cudaFree(cubuf_C);
        cudaStreamDestroy(stream);

        return 0;
    }
    ```

    compile:

    `nvcc -g -G main.cu -o main`

    run:

    `./main`

    output:

    ```
    cubuf_A:
    3.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 2.0, 
    cubuf_B:
    4.0, 1.0, 2.0, 2.0, 0.0, 4.0, 3.0, 1.0, 
    cubuf_C:
    7.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0, 3.0, 
    ```

    `cudaLaunchKernel()`，第一个参数是 kernel 函数地址，需要用`(const void *)`或`(void *)`类型转换一下，第二个参数是 grid dim，可以指定`dim3`，如果是一维的，直接指定 scalar 就可以了，第三个参数是 block dim，同参数二。

    第四个参数是 kernel 函数的参数列表，虽然指定的类型是`void**`，即`void*`的数组，但是实际传递的并不是 buffer 的 va，而是 buffer va 的 va。可以看到`void *args[3] = {&cubuf_A, &cubuf_B, &cubuf_C};`里，对`cubuf_A`等`float*`类型的变量又多加了一层取地址。不加这个会报 segment fault。

    第 5 个参数直接填 0 就可以，目前用不到。

    第 6 个参数可以填 stream，也可以填`NULL`，只不过这时要用`cudaDeviceSynchronize();`来阻塞等待 kernel launch。

* `cudaLaunchKernel()` example 2

    ```cpp
    #include <cuda_runtime.h>
    #include <stdlib.h>
    #include <stdio.h>

    void assign_cubuf_rand_int(float *cubuf, size_t num_elm)
    {
        float *buf = (float*) malloc(num_elm * sizeof(float));
        for (size_t i = 0; i < num_elm; ++i)
        {
            buf[i] = rand() % 5;
        }
        cudaMemcpy(cubuf, buf, num_elm * sizeof(float), cudaMemcpyHostToDevice);
        free(buf);
    }

    void print_cubuf(float *cubuf, size_t num_elm)
    {
        float *buf = (float*) malloc(num_elm * sizeof(float));
        cudaMemcpy(buf, cubuf, num_elm * sizeof(float), cudaMemcpyDeviceToHost);
        for (size_t i = 0; i < num_elm; ++i)
        {
            printf("%.1f, ", buf[i]);
        }
        putchar('\n');
        free(buf);
    }

    __global__ void vec_add(float *A, float *B, float *C)
    {
        int x = blockIdx.x * blockDim.x + threadIdx.x;
        C[x] = A[x] + B[x];
    }

    int main()
    {
        float *cubuf_A, *cubuf_B, *cubuf_C;
        cudaMalloc(&cubuf_A, 8 * sizeof(float));
        cudaMalloc(&cubuf_B, 8 * sizeof(float));
        cudaMalloc(&cubuf_C, 8 * sizeof(float));

        assign_cubuf_rand_int(cubuf_A, 8);
        assign_cubuf_rand_int(cubuf_B, 8);

        puts("cubuf_A:");
        print_cubuf(cubuf_A, 8);
        puts("cubuf_B:");
        print_cubuf(cubuf_B, 8);

        // void *args[3] = {&cubuf_A, &cubuf_B, &cubuf_C};
        void **args = (void**) malloc(3 * sizeof(void*));
        args[0] = &cubuf_A;
        args[1] = &cubuf_B;
        args[2] = &cubuf_C;
        cudaLaunchKernel((const void *) vec_add, dim3(2, 1, 1), dim3(4, 1, 1), args, 0, NULL);
        // cudaStreamSynchronize(stream);
        cudaDeviceSynchronize();

        puts("cubuf_C:");
        print_cubuf(cubuf_C, 8);

        cudaFree(cubuf_A);
        cudaFree(cubuf_B);
        cudaFree(cubuf_C);

        return 0;
    }
    ```

    output:

    ```
    cubuf_A:
    3.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 2.0, 
    cubuf_B:
    4.0, 1.0, 2.0, 2.0, 0.0, 4.0, 3.0, 1.0, 
    cubuf_C:
    7.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0, 3.0,
    ```