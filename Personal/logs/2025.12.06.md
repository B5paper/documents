* 高斯分布（正态分布）的推导

    高斯函数（正态分布）的发现是科学史上的重要里程碑，由高斯和拉普拉斯分别独立发现。最初的动机是解决测量误差问题。

    * 基本假设（公理系统）

        高斯函数的推导基于以下合理假设：

        1. 误差对称性假设

            误差围绕真值对称分布：

            $p(\varepsilon) = p(- \varepsilon)$

            其中$\varepsilon = 测量值 - 真值$

        2. 最大似然原理

            函数中最可能的参数值应该是使所有观测值出现的概率乘积最大的值。

        3. 独立同分布假设

            多次测量误差相互独立。

    * 推导过程

        1. 设定问题框架

            设：

            * 真值：$\mu$

            * 测量值：$x_1$, $x_2$, $\dots$, $x_n$

            * 误差：$\varepsilon_i = x_i - \mu$

            * 误差概率密度函数：$\varphi(\varepsilon)$

            根据独立性，我们可以计算出观测到这些数据的联合概率：

            $$L(\mu) = \varphi(x_1 - \mu) \cdot \varphi(x_2 - \mu) \cdot \dots \cdot \varphi(x_n - \mu)$$

        2. 最大似然估计

            对$L(\mu)$取对数（取对数后，求到的极值和原问题等价吗？是否存在取对数后，极值与原函数不相同的情况？）：

            $$\ln L(\mu) = \sum_i \ln \varphi(x_i - \mu)$$

            最大化条件（为什么是最大化，而不是最小化？）：

            $$\frac{\mathrm d \ [\ln L(\mu)]} {\mathrm d \ \mu} = 0$$

            即：

            $$\sum \frac{\varphi'(x_i - \mu)} {\varphi(x_i - \mu)} = 0$$

        3. 引入关键函数

            令：

            $$\Psi(\varepsilon) = \frac{\varphi'(\varepsilon)} {\varphi(\varepsilon)}$$

            则方程变为：

            $$\sum_i \Psi(x_i - \mu) = 0$$

        4. 高斯的关键洞察

            高斯意识到，如果取算术平均作为 $\mu$ 的估计：

            $$\hat \mu = \frac{x_1 + x_2 + \dots + x_n} {n}$$

            那么对于任意 $a$, $b$ （为什么？不懂）：

            $$\sum \Psi(x_i - (a \cdot x_j + b \cdot x_k)) = 0$$

            这要求 $\Psi$ 必须是线性函数 (依然不懂)：

            $$\Psi (\varepsilon) = k \cdot \varepsilon$$

        5. 求解微分方程

            由
            
            $$\Psi(\varepsilon) = \varphi'(\varepsilon) / \varphi(\varepsilon) = k \cdot \varepsilon$$

            解这个微分方程：

            $$\mathrm d \, \varphi / \varphi = k \varepsilon \ \mathrm d \, \varepsilon$$

            两边积分：

            $$\ln \varphi(\varepsilon) = (k / 2) \varepsilon^2 + C$$

            所以：

            $$φ(ε) = A \cdot \exp(kε²/2)$$

        6. 确定常数

            因为概率密度函数必须满足：

                归一化：∫φ(ε)dε = 1

                对称性：φ(ε) = φ(-ε)

                衰减性：当|ε|→∞时，φ(ε)→0

            这要求k必须为负数，令 k = -1/σ²

            则：

            φ(ε) = A · exp(-ε²/(2σ²))

        7. 归一化计算

            计算归一化常数A：

            ∫_{-∞}^{∞} A · exp(-ε²/(2σ²)) dε = 1

            利用高斯积分公式：

            ∫_{-∞}^{∞} exp(-αx²) dx = √(π/α)

            令 α = 1/(2σ²)，则：

            ∫ exp(-ε²/(2σ²)) dε = √(2πσ²)

            所以：

            A = 1/√(2πσ²)

        8. 最终形式

            得到标准的高斯分布：

            φ(ε) = 1/√(2πσ²) · exp(-ε²/(2σ²))

* python 求解高斯函数

    ```py
    import numpy as np
    import matplotlib.pyplot as plt
    from scipy.integrate import quad
    import sympy as sp

    # 符号推导验证
    print("="*60)
    print("符号推导验证")
    print("="*60)

    # 定义符号
    ε, σ, A, k = sp.symbols('ε σ A k', positive=True, real=True)

    # 1. 从微分方程开始
    print("\n1. 解微分方程: dφ/dε / φ = k·ε")

    # 定义微分方程
    φ = sp.Function('φ')
    ode = sp.Eq(φ(ε).diff(ε)/φ(ε), k*ε)

    # 解微分方程
    solution = sp.dsolve(ode)
    print(f"微分方程的解: {solution}")

    # 2. 应用边界条件
    print("\n2. 应用概率密度函数的约束条件")

    # 解的形式: φ(ε) = C1*exp(k*ε**2/2)
    C1 = sp.symbols('C1')
    φ_expr = C1 * sp.exp(k * ε**2 / 2)

    # 约束1: 当|ε|→∞时，φ(ε)→0 => k必须为负
    print(f"衰减性要求: k < 0")
    k_value = -1/σ**2
    φ_expr = φ_expr.subs(k, k_value)
    print(f"令 k = -1/σ²: φ(ε) = {φ_expr}")

    # 约束2: 归一化条件
    print("\n3. 计算归一化常数")

    # 计算积分
    integral = sp.integrate(φ_expr, (ε, -sp.oo, sp.oo))
    print(f"积分结果: ∫φ(ε)dε = {sp.simplify(integral)}")

    # 令积分等于1，解出C1
    C1_solution = sp.solve(sp.Eq(integral, 1), C1)[0]
    print(f"归一化常数 C1 = {sp.simplify(C1_solution)}")

    # 最终形式
    φ_final = φ_expr.subs(C1, C1_solution)
    print(f"\n4. 最终高斯分布:")
    print(f"φ(ε) = {sp.simplify(φ_final)}")
    print("="*60)

    # 数值验证
    print("\n数值验证:")
    print("-"*40)

    def gaussian(x, mu=0, sigma=1):
        """标准高斯函数"""
        return 1/(sigma*np.sqrt(2*np.pi)) * np.exp(-0.5*((x-mu)/sigma)**2)

    # 测试不同sigma
    sigmas = [0.5, 1.0, 2.0]
    x = np.linspace(-5, 5, 1000)

    plt.figure(figsize=(12, 8))

    for i, sigma in enumerate(sigmas):
        y = gaussian(x, sigma=sigma)
        
        # 数值积分验证归一化
        integral_val, error = quad(gaussian, -np.inf, np.inf, args=(0, sigma))
        
        plt.subplot(2, 2, i+1)
        plt.plot(x, y, 'b-', linewidth=2, label=f'σ={sigma}')
        plt.fill_between(x, y, alpha=0.3)
        plt.title(f'高斯分布 σ={sigma}\n归一化积分={integral_val:.8f} (±{error:.2e})')
        plt.xlabel('x')
        plt.ylabel('概率密度')
        plt.grid(True, alpha=0.3)
        plt.legend()

    # 可视化中心极限定理
    plt.subplot(2, 2, 4)
    np.random.seed(42)

    # 模拟不同样本量的均值分布
    sample_sizes = [1, 5, 20, 100]
    colors = ['red', 'green', 'blue', 'purple']

    for n, color in zip(sample_sizes, colors):
        # 从均匀分布采样，计算均值
        n_samples = 10000
        means = []
        
        for _ in range(n_samples):
            samples = np.random.uniform(-1, 1, n)  # 均匀分布[-1,1]
            means.append(np.mean(samples))
        
        # 绘制直方图
        plt.hist(means, bins=50, density=True, alpha=0.5, 
                color=color, label=f'n={n}')
        
        # 理论正态分布
        if n > 1:
            # 均匀分布的方差 = (b-a)²/12 = 1/3
            theoretical_sigma = np.sqrt(1/(3*n))
            x_fine = np.linspace(-1, 1, 200)
            y_theory = gaussian(x_fine, sigma=theoretical_sigma)
            plt.plot(x_fine, y_theory, color=color, linestyle='--', linewidth=2)

    plt.title('中心极限定理演示')
    plt.xlabel('样本均值')
    plt.ylabel('概率密度')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()
    ```