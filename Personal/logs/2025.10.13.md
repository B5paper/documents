* `plt.figure()`

    syntax:

    ```py
    plt.figure(num=None, figsize=None, dpi=None, facecolor=None, edgecolor=None, frameon=True, FigureClass=<class 'matplotlib.figure.Figure'>, clear=False, **kwargs)
    ```

    * num: 图形标识符（数字或字符串）

    * figsize: 图形尺寸（宽度, 高度），单位为英寸

    * dpi: 分辨率，每英寸点数

    * facecolor: 图形背景颜色

    * edgecolor: 图形边框颜色

    * clear: 如果为 True 且图形已存在，则清除该图形

    example:

    * 基本用法

        ```py
        import matplotlib.pyplot as plt
        import numpy as np

        # 创建数据
        x = np.linspace(0, 10, 100)
        y = np.sin(x)

        # 创建图形
        plt.figure()
        plt.plot(x, y)
        plt.title('基础图形')
        plt.show()
        ```

    * 指定图形尺寸

        ```py
        # 创建指定大小的图形
        plt.figure(figsize=(8, 6))
        plt.plot(x, y, 'r-', linewidth=2)
        plt.title('自定义尺寸图形')
        plt.grid(True)
        plt.show()
        ```

    * 多图形管理

        ```py
        # 创建第一个图形
        plt.figure(1, figsize=(6, 4))
        plt.plot(x, np.sin(x), 'b-')
        plt.title('图形 1: 正弦函数')

        # 创建第二个图形
        plt.figure(2, figsize=(6, 4))
        plt.plot(x, np.cos(x), 'g-')
        plt.title('图形 2: 余弦函数')

        # 切换回第一个图形并添加内容
        plt.figure(1)
        plt.plot(x, np.cos(x), 'r--', alpha=0.5)
        plt.legend(['sin', 'cos'])

        plt.show()
        ```

    * 自定义背景和分辨率

        ```py
        # 高分辨率、自定义背景
        plt.figure(figsize=(10, 6), dpi=100, facecolor='lightgray')
        plt.plot(x, np.sin(x), label='sin(x)')
        plt.plot(x, np.cos(x), label='cos(x)')
        plt.legend()
        plt.title('高分辨率自定义背景图形')
        plt.grid(True, alpha=0.3)
        plt.show()
        ```

    * 清除现有图形

        ```py
        # 先创建一个图形
        plt.figure(1)
        plt.plot(x, y)
        plt.title('原始图形')

        # 清除并重新绘制
        plt.figure(1, clear=True)
        plt.plot(x, np.tan(x))
        plt.title('清除后重新绘制的图形')
        plt.ylim(-5, 5)
        plt.show()
        ```

    * 使用子图

        ```py
        # 创建图形并添加子图
        fig = plt.figure(figsize=(12, 4))

        # 添加第一个子图
        ax1 = fig.add_subplot(131)
        ax1.plot(x, np.sin(x))
        ax1.set_title('正弦函数')

        # 添加第二个子图
        ax2 = fig.add_subplot(132)
        ax2.plot(x, np.cos(x), 'r-')
        ax2.set_title('余弦函数')

        # 添加第三个子图
        ax3 = fig.add_subplot(133)
        ax3.plot(x, np.exp(-x), 'g-')
        ax3.set_title('指数衰减')

        plt.tight_layout()
        plt.show()
        ```

    * 保存高质量图形

        ```py
        # 创建高分辨率图形用于保存
        plt.figure(figsize=(8, 6), dpi=150)
        x = np.linspace(0, 2*np.pi, 100)
        y1 = np.sin(x)
        y2 = np.cos(x)

        plt.plot(x, y1, 'b-', label='sin(x)', linewidth=2)
        plt.plot(x, y2, 'r--', label='cos(x)', linewidth=2)
        plt.xlabel('x')
        plt.ylabel('y')
        plt.title('三角函数')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # 保存为高质量图片
        plt.savefig('high_quality_plot.png', dpi=300, bbox_inches='tight')
        plt.show()
        ```

* n 维空间

    设$n$为取定的一个自然数，我们用$\mathbf R^n$表示$n$元有序数组$(x_1, x_2, \cdots, x_n)$的全体所构成的集合，即

    $$\mathbf R^n = \mathbf R \times \mathbf R \times \cdots \times \mathbf R = \{ (x_1, x_2, \cdots, x_n) \ \vert \ x_i \in \mathbf R, i = 1, 2, \cdots, n \}$$

    注：

    1. 感觉还不如先定义 n 维向量比较好，等把 n 维向量用熟了，再定义 n 维空间。

    $\mathbf R^n$中的元素$(x_1, x_2, \cdots, x_n)$有时也用单个字母$\boldsymbol x$来表示，即
    
    $$\boldsymbol x = (x_1, x_2, \cdots, x_n)$$

    在$\mathbf R^n$中定义线性运算如下：

    设$\boldsymbol x = (x_1, x_2, \cdots, x_n)$，$\boldsymbol y = (y_1, y_2, \cdots, y_n)$为$\mathbf R^n$中任意两个元素，$\lambda \in \mathbf R$，规定

    $$\boldsymbol x + \boldsymbol y = (x_1 + y_1, x_2 + y_2, \cdots, x_n + y_n)$$

    $$\lambda x = (\lambda x_1, \lambda x_2, \cdots, \lambda x_n)$$

    这样定义了线性运算的集合$\mathbf R^n$称为$n$维空间。

    注：

    1. 这个明显是线性空间的定义，但是没有线性代数/矩阵论里写得好。为什么这里不提一嘴和别的概念的联系和不同之处？为什么没有 see also 部分？

* 设备树

    设备树 是一个描述硬件配置的数据结构，它以一种特定的格式（通常是一个.dts文件）来详细说明一个计算机系统里有哪些设备，它们的类型、地址、中断号以及各种可配置参数。

    设备树在系统启动时由 Bootloader（如 U-Boot）传递给操作系统内核（如 Linux）。内核通过解读这张“地图”，就知道自己运行在什么样的硬件之上，从而动态地加载正确的驱动程序并初始化对应的设备。

    在 x86 架构中，BIOS/UEFI 提供标准接口来枚举设备，内核可以询问“这里有什么硬件？”（即探测）。

    在 ARM 架构中，情况非常复杂，SoC 种类繁多，板卡设计多样。如果为每一种“SoC + 板卡”的组合都编译一个特定的内核，那将是一场维护噩梦。设备树就是为了解决这个问题而诞生的。

    设备树的核心作用是解耦，将硬件描述和操作系统内核分离开来，从而可以实现一个内核，多种硬件。

* 设备树源文件（.dts）

    设备树源文件（.dts）是一种类似 JSON 的层次化结构，主要包含以下元素：

    1. 节点：代表一个设备或一个总线。树状结构的根是 /。

    2. 属性：附着在节点上的键值对，用于描述设备的特性。

        * `compatible`：最重要的属性。它是一个字符串列表，内核通过它来匹配最适合的设备驱动程序。例如：`compatible = "ti,omap3-uart"`; 表示这个设备与德州仪器的 OMAP3 串口驱动兼容。

        * `reg`：定义设备在父总线地址空间内的内存映射地址和长度。

        * `interrupts`：定义设备使用的中断号。

        * `status`：指示设备状态，如 `"okay"`（启用）或 `"disabled"`（禁用）。

        * `model` & `compatible：描述板卡和` SoC 的型号。

    工作流程简述

    1. 编写：硬件工程师或驱动开发者根据实际硬件编写设备树源文件（.dts）。

    2. 编译：使用设备树编译器（dtc）将人类可读的 .dts 文件编译成机器可读的二进制格式——设备树 blob（.dtb 文件）。

    3. 传递：Bootloader 在启动内核时，将 .dtb 文件在内存中的地址传递给内核。

    4. 解析：内核启动初期，解析 .dtb 文件，根据 compatible 属性匹配驱动程序，并根据 reg、interrupts 等属性初始化并注册平台设备。

    example:

    `dts`:

    ```dts
    // 这是一个极其简化的示例
    /dts-v1/;

    / {
        model = "My Awesome Board";
        compatible = "my-company,my-board"; // 板卡兼容性

        cpus {
            cpu@0 {
                compatible = "arm,cortex-a53";
            };
        };

        memory@80000000 { // 内存节点
            device_type = "memory";
            reg = <0x80000000 0x20000000>; // 起始地址 0x80000000，大小 512MB
        };

        uart0: serial@ff000000 { // 串口设备，别名为 uart0
            compatible = "ns16550a"; // 匹配标准的 16550 串口驱动
            reg = <0xff000000 0x1000>; // 寄存器地址范围
            interrupts = <10>; // 使用中断号 10
            status = "okay";
        };
    };
    ```

* c++ 中的 string & 在 vscode 中，debug 断点模式下，鼠标悬停不显示内容

    下面是实测结果：

    ```cpp
    #include <string>
    #include <unordered_map>
    using namespace std;

    int main() {
        string str = "hello, world";  // 显示
        string &str_2 = str;  // 不显示
        const string &str_3 = str;  // 不显示
        const string &str_4 = "hello, world";  // 不显示

        unordered_map<string, string> umap {
            {"hello", "world"},
            {"nihao", "zaijian"}
        };
        string &str_val = umap["hello"];  // 不显示
        const string &con_str_val = umap["nihao"];  // 不显示
        return 0;
    }
    ```

* `asm("int $0x3B");`

    触发一个软中断.

    作用解析

    * `int`：x86 架构的软中断指令（Interrupt）

    * `0x3B`：中断向量号（59号中断）

* `remove_pointer_t`

    remove_pointer_t 是 C++ 标准库中的一个类型特性（type trait），其作用是移除类型的指针修饰符。

    作用：

    如果 T 是指针类型，remove_pointer_t<T> 会得到指针所指向的类型

    如果 T 不是指针类型，remove_pointer_t<T> 会得到 T 本身

    注意

    * 只移除最外层的指针修饰符

    * 对于多级指针需要多次应用才能得到最终的非指针类型

    * 不会影响 const、volatile 等其他类型修饰符

* python 中判断一个 key 是否在 dict 中

    * 使用`in`关键字

    * 使用 get() 方法

        ```py
        my_dict = {'a': 1, 'b': 2, 'c': 3}

        # 如果 key 不存在，返回 None 或默认值
        value = my_dict.get('a')  # 返回 1
        value = my_dict.get('d')  # 返回 None
        value = my_dict.get('d', 'default')  # 返回 'default'

        # 判断存在性
        if my_dict.get('a') is not None:
            print("Key 'a' exists")
        ```

    * 使用 keys() 方法

        ```py
        my_dict = {'a': 1, 'b': 2, 'c': 3}

        if 'a' in my_dict.keys():
            print("Key 'a' exists")
        ```

    * 使用 try-except 块

        ```py
        my_dict = {'a': 1, 'b': 2, 'c': 3}

        try:
            value = my_dict['d']
            print("Key 'd' exists")
        except KeyError:
            print("Key 'd' does not exist")
        ```

* python 中没有很好支持 do while 的方法，只能用 while + if + break 来模拟

* Mean Square Error (L2 loss)

    L2 computes the average of the squared differences between the predicted and actual values.

    The main idea behind squaring is to penalise the model for large difference so that the model avoid larger differences. 

    $$MSE = \frac 1 n \sum_{i=1}^n (y_i - \hat y_i)^2$$

    Here,

    * $n$ represents the total number of observations or samples,

    * $y_i$ represents the actual or observed value for the ith sample,

    * $\hat y_i$ represents the predicted or estimated value for the ith sample.

    syntax:

    ```py
    torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')
    ```

    example:

    ```py
    import torch
    from torch import nn
    #initialising the loss function
    loss = nn.MSELoss()
    #randomly initialising the input and the target value...input is considered as predicted value here.
    input = torch.randn(2, 4, requires_grad=True)
    target = torch.randn(2, 4)
    #passing both the values inside the loss function.
    output = loss(input, target)
    #backpropagation
    output.backward()
    print(output)
    ```

    output:

    ```
    tensor(1.6697, grad_fn=<MseLossBackward0>)
    ```

    Disadvantages:

    Sensitive to outliers due to the squaring operation, which deviates the results in the optimization process.

* Huber Loss

    This loss is used while tackling regression problems especially when dealing with outliers.

    $$\mathrm{HuberLoss}(x, \mathrm{target}, \delta) = 
    \frac 1 N \sum_i
    \left\{
    \begin{aligned}
        &\frac 1 2 (x_i - \mathrm{target}_i)^2 \quad \text{if } \lvert x_i - \mathrm{target}_i \rvert \leq \delta \\
        &\delta \left( \lvert x_i - \mathrm{target}_i \rvert - \frac 1 2 \delta \right) \quad \text{otherwise}
    \end{aligned}    
    \right.$$

    Here,

    * x represents the predicted values,target represents the ground truth or target values,

    * δ is a parameter controlling the threshold for switching between quadratic and linear loss

    It combines both MAE( Mean Absolute Error ) and MSE( Mean Squared Error) and which loss will be used depends upon the delta value.

    syntax:

    ```py
    torch.nn.HuberLoss(reduction='mean', delta=1.0)
    ```

    Advantage:

    * Less sensitive to outliers than MSE but still provide a more balanced approach to evaluating the performance of regression models compared to MAE.

    Disadvantage:

    * Introduces a new hyper parameter and the optimization of that leads to more complexity in the model.

    MAE, MSE and Huber loss are used in regression problems but, which one should we use. MSE can be used when you want to penalize larger errors more heavily. It's useful when the data does not have significant outliers and you assume that the errors are normally distributed. MAE can be used when you want robust loss function that is less affected by outliers. And Huber loss can be used when you want to compromise the benefits of both MAE and MSE. 

* convolution

    $$(f ∗ g) (t)= \int_{-\infty}^{\infty} ​f(\tau) g(t − \tau) d\tau$$

    Where f and g are functions representing the image and the filter respectively, and * denotes the convolution operator.

* `<sys/types.h>`

    * 定义基本系统数据类型：包含许多标准系统数据类型的定义

    * 提供类型别名：如 pid_t（进程ID）、uid_t（用户ID）、gid_t（组ID）、off_t（文件偏移）、size_t（大小类型）等

* `<sys/stat.h>`

    * 文件状态信息：包含获取文件信息的函数和数据结构

    * 定义 struct stat：用于存储文件的各种属性（大小、权限、时间戳等）

    * 文件模式常量：如 S_IRUSR（用户读权限）、S_IWUSR（用户写权限）等

    * 主要函数：stat(), fstat(), lstat() 等文件状态查询函数

* `<fcntl.h>`

    文件控制选项：定义文件操作的各种控制常量和函数

    文件打开标志：如 O_RDONLY（只读）、O_WRONLY（只写）、O_RDWR（读写）、O_CREAT（创建文件）等

    文件描述符操作：包含 open(), creat(), fcntl() 等函数的声明和相关常量

* `pci_find_bus()`

    根据总线号查找并返回指定的 PCI 总线结构。

    syntax:

    ```c
    #include <linux/pci.h>

    struct pci_bus *pci_find_bus(int bus);
    ```

    在系统的 PCI 总线列表中搜索具有特定总线号的 PCI 总线, 接收一个总线号作为参数（通常为 0-255 范围内的整数）

    返回值:

    * 如果找到对应的总线，返回指向 struct pci_bus 的指针

    * 如果未找到，返回 NULL 指针