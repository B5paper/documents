* 从 rdma project 中拿出来的 cache

    * [ ] ln 是否能创建文件夹的 hard link?

    * mpi tutorial 的 github repo: <https://github.com/mpitutorial/mpitutorial/tree/gh-pages>

    * [ ] 调研`ssh-add`，`ssh-agent`的作用

    * mpirun 使用 hostname 和 ip addr 的两个注意事项

        * 如果使用 hostname，那么是去`~/.ssh/config`文件中找对应的配置，连接 ssh 

        * 如果使用 ip addr，那么 route 的路由顺序不对可能会导致无法连通

    * 如果需要对不同设备，函数做出不同的行为，一种方法增加一个`enum`类型的函数参数，判断调用者的情况。另一种方法是增加一个编译宏，然后使用`#ifdef xxx`来检测，这样可以在编译时判断调用函数的主体的情况。

        为了只编译一份 lib 就适用多种情况，目前采用的是`enum`方案。

    * vllm pynccl 中目前看来改动的文件是`/home/test/miniconda3/envs/vllm/lib/python3.10/site-packages/vllm/distributed/parallel_state.py`

        看起来比较重要的几段代码：

        ```python
        with self.pynccl_comm.change_state(enable=True, stream=torch.cuda.current_stream()):
            self.pynccl_comm.send(tensor, dst=self.ranks[dst])
        ```

        ```python
        with self.pynccl_comm.change_state(enable=True, stream=torch.cuda.current_stream()):
            self.pynccl_comm.recv(tensor, src=self.ranks[src])
        ```

        ```python
        pynccl_comm = self.pynccl_comm
        if pynccl_comm is not None and not pynccl_comm.disabled:
            pynccl_comm.send(tensor, dst)
        else:
            with xxxx

        # torch.distributed.send(tensor, self.ranks[dst], self.device_group)
        ```

    * [ ] 调研`fprintf(stderr," Internal error, existing.\n");`的用法

    * [ ] 调研 diff 命令的用法

    * [ ] 调研 pynccl 的用法

    * [ ] 调研 docker 中 app 的调试方法

    * [ ] 调研 nccl app

    * [ ] 调研 makefile 的 submodule

    * [ ] 调研`MPI_Probe`, <https://mpitutorial.com/tutorials/dynamic-receiving-with-mpi-probe-and-mpi-status/>

    * [ ] 调研使用`MPI_ERROR`接收未知长度数据