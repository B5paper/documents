* [v] 调研 pci host bridge

    feedback:

    1. 发现本机资源的几个关键函数：`ncclTopoGetSystem()` -> `ncclTopoComputePaths()` -> `ncclTopoTrimSystem()`

        目前看来是在`ncclTopoComputePaths()`中判断了 pcie p2p 不可用。

        这里的不可用有可能是逻辑判断有问题，也有可能是上一个函数`ncclTopoGetSystem()`在获取资源时，获取的原始数据有误。

    2. 在建立 ring 连接时（`ncclTransportRingConnect()`），调用`ncclTransportP2pSetup()`建立 p2p 连接

        其中，会调用`selectTransport()` -> `transportComm->setup()`，最终调用到`shmRecvSetup()`。

        显然`setup()`函数指针在前面已经被替换成了`shmRecvSetup()`。

        目前看来，应该是用`struct ncclTransport shmTransport;`完成的替换，这个结构体里包含了 proxy 所需要用到的所有 shm 相关的函数。

    3. `shmTransport`既包含在`struct ncclTransport* ncclTransports[NTRANSPORTS]`数组中，可以用 transport 索引直接调用到，对应的数组的索引是 1

        `p2pTransport`对应数组的索引是 0，`netTransport`对应 2，`collNetTransport`对应 3。

    4. `ncclTransports`在五处地方被使用
    
        1. `proxyConnInit()`未被调用

        2. `proxyFree()`：未调用

        3. `ncclProxyConnect()`：未调用

        4. `selectTransport()`：调用

        5. `ncclTopoComputePaths()`

        说明全程没有用到 proxy。无法简单看代码看出逻辑，可能只要在同一台机器上就不需要创建 proxy。

        猜想：这个可能是在`groupLaunch()` -> `asyncJobLaunch()`阶段就判断出了不需要创建 proxy connect。

    5. cached tabs

        * NCCL源码解析①：初始化及ncclUniqueId的产生

            <https://zhuanlan.zhihu.com/p/614746112>

        * NCCL源码解析②：Bootstrap网络连接的建立

            <https://zhuanlan.zhihu.com/p/620499558>

        * NCCL源码解析③：机器内拓扑分析

            <https://zhuanlan.zhihu.com/p/625606436>

        * NCCL源码解析④：建图过程

            <https://zhuanlan.zhihu.com/p/640812018>

        * NCCL源码解析⑥：Channel搜索

            <https://zhuanlan.zhihu.com/p/653440728>

        * NCCL源码解析⑦：机器间Channel连接

            <https://zhuanlan.zhihu.com/p/658868934>

        * NCCL的不足，集合通信库初步调研 NCCL、BCCL、TCCL、ACCL、HCCL

            <https://blog.csdn.net/lianghuaju/article/details/139470668>

    6. cached tabs

        vscode 多线程调试: <https://zhuanlan.zhihu.com/p/704723451>

    7. 多线程调试时锁定单线程

        GDB scheduler-locking 命令详解

        <https://www.cnblogs.com/pugang/p/7698772.html>

    8. gdb+vscode进行调试12——使用gdb调试多线程 如何实现只对某个线程断点，其他线程正常运行

        <https://blog.csdn.net/xiaoshengsinian/article/details/130151878?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ECtr-1-130151878-blog-140669886.235%5Ev43%5Epc_blog_bottom_relevance_base4&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ECtr-1-130151878-blog-140669886.235%5Ev43%5Epc_blog_bottom_relevance_base4&utm_relevant_index=1>

* [ ] process 1 url

* [ ] 调研 HPC 通信 ppt

    feedback:

    1. guideline

        1. optimizing an matrix multiplying task

            * OpenMP

                多线程，不支持多进程，多 node

                不支持 avx512 等 SIMD 指令，不支持 GPU，不支持 MKL，BLAS 等数学运算库

            * OpenMPI

                设计一系列集合通信原语（collective communication primitives），支持更大的集群。

                scatter, gather, reduce, all scatter, all gather, all reduce, broadcast

                Barrier

                重新优化矩阵乘法的代码

                OpenMPI 使用 socket 进行多进程，多 node 通信。

                OpenMPI 支持网络拓扑探测，找到通信效率最高的拓扑，常用拓扑结构为 ring 和 tree（ring 为什么更优？）

            * 集合通信与深度学习

                训练时梯度的依赖（all reduce）, inference 时的计算（send recv）

        2. NCCL 与 chunk pipeline

            nccl 是在 OpenMPI 的基础上提出 chunk pipeline 的方法，使得传输效率更高。

            nccl 的主要拓展：

            * openmpi 只支持 socket 进行跨进程，跨节点通信，nccl 增加了 pcie p2p, shared host memory, infiniband rdma, gpu direct rdma, nvlink, nvswitch 的支持

            * openmpi 调用操作系统的 socket 接口，效率较低，nccl 采用多线程异步 + 主动 poll 事件的方式，不处理中断，使计算任务、事件处理和数据传输三者代码隔离，效率更高，通常会几个 cpu 线程跑满

            * openmpi 的数据传输和计算任务放在一起，nccl 由于做了异步代码隔离，所以可以起多个线程多个 channel 进行通信，使得 cpu 性能不会成为瓶颈

