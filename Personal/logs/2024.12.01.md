* incontext learning 与复杂系统的猜想

    猜想：假如大模型可以靠 inference 完成复杂问题的推理，那么说明大模型在训练时不光学到了指定词组/句子后的可能模式，还学到了不同知识节点之间的复杂相互作用关系。

    验证：假如只保留复杂关系，对前端表示做替换，那么不影响最终的输出结果。

* nvcc 加上`-g`后支持 host code 调试，加上`-G`后支持 cuda kernel code 调试

* nvcc 编译不同的架构支持`-gencode arch=compute_70,code=sm_70`

    如果硬件是 80 的兼容性，那么这个硬件支持使用 70 兼容性编译出来的 code。

    相反，如果硬件是 70 的兼容性，那么它跑不起来使用 80 兼容性编译出来的 code.

* cuda-gdb hit 断点时，可以使用`info cuda kernels`查看当前的 kernel 函数，sm，block, grid, device 使用情况等信息。