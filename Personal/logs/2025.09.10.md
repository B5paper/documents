* ssh 远程后台执行命令后直接返回

    核心要求有两点：

    1. 需要在命令后添加`&`

    2. stdout 和 stderr 必须重定向到文件

    example:

    * `ssh user@host "sleep 5 &"`

        不行，因为 stdout 和 stderr 仍在占用当前 shell session.

    * `ssh user@host "sleep 5 & disown"`

        不行，因为 ssh 执行的是非交互 shell，`disown`无法将 job 脱离当前 shell。

    * `ssh user@host "sleep 5 > /dev/null 2>&1 &"`

        OK，stdout 和 stderr 被重定向到`/dev/null`文件，并且命令的最后有`&`表示在后台执行。此时 ssh 会立即返回。

    * `ssh user@host "sleep 5 2>&1 > /dev/null &"`

        不行，stderr 指向 shell, stdout 指向`/dev/null`。

        从左到右解析命令，`2>&1`表示将 stderr 指向当前的 stdout (shell)，`> /dev/null`表示将 stdout 指向`/dev/null`，但是不改变 stderr。此时 stderr 仍指向 shell，而 stdout 指向`/dev/null`。

    * `ssh user@host "sleep 5 && echo hello > /dev/null 2>&1 &"`

        不行，首先`&`作用于`sleep 5 && echo hello`，即
        
        `(sleep 5 && echo hello > /dev/null 2>&1) &`

        其次`> /dev/null`和`2>&1`只作用于`echo hello`。

        此时`sleep 5`的 stdout / stderr 都定向到 shell。
        
        另外，`sleep 5 && echo hello > /dev/null 2>&1`可能会起一个子 shell，这个子 shell 的 stdout / stderr 都未重定向。
        
        因此 ssh 无法立即返回。

    * `ssh user@host"sleep 5 > /dev/null 2>&1 && echo hello > /dev/null 2>&1 &"`

        不行，很明显了，即使对两个子 command 都重定向，也不行。说明两个子 command 被合成为一个整体的 command。

    * `ssh host@user "(sleep 5 && echo hello) > /dev/null 2>&1 &"`

        OK。再次验证了上面的想法。

    * `ssh user@host "nohup (sleep 5 && echo hello) > /dev/null 2>&1 &"`

        不行。

        前面的 case 都是 ssh 可以立即返回，但是 ssh 在返回时会发送 sighup 信号，导致实际上任务会中断，nohup 可以解决这个问题，但是 nohup 会带来新的问题。

        语法错误，报错：

        ```
        bash: -c: line 0: syntax error near unexpected token `sleep'
        bash: -c: line 0: `nohup (sleep 5 && echo hello) > /dev/null 2>&1 &'
        ```

        `(sleep 5 && echo hello)`不是一个命令，是一个子进程命令组合，`nohup`只接收单个命令，不接收子进程命令。

    * `ssh user@host "nohup sleep 5 && echo hello > /dev/null 2>&1 &"`

        不行，`nohup`只作用于`sleep 5`。

    * `ssh user@host "nohup bash -c 'sleep 5 && echo hello' > /dev/null 2>&1 &"`

        OK。`nohup`只作用于`bash -c 'sleep 5 && echo hello'`，`> /dev/null`，`2>&1`以及`&`也作用于`bash -c`。这样既可以让 ssh 立即返回，也不会因为 ssh 的返回而中断任务。

* `command_1 && command_2 &`里，`&`作用于`(command_1 && command_2)`。

* `devm_ioremap_resource()`

    将 I/O 内存资源（通常是 MMIO 寄存器空间）映射到内核虚拟地址空间，并且由 设备管理器（device-managed, `devm_`）自动管理其生命周期.

    syntax:

    ```c
    void __iomem *devm_ioremap_resource(struct device *dev, struct resource *res);
    ```

    * res：指向已获取的 struct resource *，通常是 IORESOURCE_MEM 类型。

    返回值：

    成功：返回映射后的内核虚拟地址（void __iomem *）。

    失败：返回错误指针，使用 IS_ERR() 检查。

    作用总结:

    1. 获取资源：先调用 platform_get_resource() 或 pci_get_resource() 得到 struct resource *。

    2. 检查资源有效性：函数内部会调用 request_mem_region() 确保资源未被占用。

    3. 映射 I/O 内存：使用 ioremap() 将物理地址映射到内核虚拟地址。

    4. 自动释放：使用 devm 机制，设备卸载时自动调用 iounmap() 并释放资源。

* `-rpath-link`

    -rpath-link 是 GCC/ld 链接器选项，用于在 动态链接（shared library） 时指定额外的 库搜索路径

    example:

    ```bash
    gcc main.o -o myprog -L/usr/lib/mylibs -lmylib -Wl,-rpath-link,/usr/lib/mylibs
    ```

    解释：

    * `-L/usr/lib/mylibs`：告诉链接器查找`-lmylib`的路径。

    * `-Wl,-rpath-link,/usr/lib/mylibs`：告诉链接器，如果`libmylib.so`还依赖其他库，去`/usr/lib/mylibs`查找它们。

    * 不会在最终可执行文件中嵌入`/usr/lib/mylibs`。

    `-L`只能用来查找`-l`指定的库，如果要找`-l`指定的库的依赖库 (transitive shared libraries)，只能使用`-rpath-link`。

* makefile 中，变量与定义间的空格

    ```makefile
    VAR=foo       # 值是 "foo"
    VAR =foo      # 值是 "foo"
    VAR= foo      # 值是 " foo"（前面多了一个空格！）
    VAR = foo     # 值是 " foo"（同样多一个空格）
    ```

    推荐写法:

    ```makefile
    KERNEL_DIR := /usr/xxx   # 立即展开赋值
    ```

* `host`

    一个 DNS 查询工具

    常见用法:

    * 查询域名对应的 IP

        `host www.example.com`

        输出该域名的 A/AAAA 记录。

        example:

        ```bash
        host www.google.com
        ```

        output:

        ```
        www.google.com has address 142.250.71.196
        www.google.com has IPv6 address 2404:6800:4005:816::2004
        ```

    * 查询 IP 对应的域名（反向解析）

        `host 8.8.8.8`

        输出 PTR 记录。

        example:

        ```bash
        host 8.8.8.8
        ```

        output:

        ```
        8.8.8.8.in-addr.arpa domain name pointer dns.google.
        ```

    * 指定查询记录类型

        ```bash
        host -t MX example.com   # 查询邮件服务器记录
        host -t NS example.com   # 查询域名服务器
        ```

    * 指定 DNS 服务器

        ```bash
        host www.example.com 8.8.8.8
        ```

        使用 Google DNS 来解析。

        (如果想取消这个映射，该怎么办？)

* torch 创建 tensor 的常见方法

    ```py
    import torch

    tensor_1d = torch.tensor([1, 2, 3])
    print("1D Tensor (Vector):")
    print(tensor_1d)
    print()

    tensor_2d = torch.tensor([[1, 2], [3, 4]])
    print("2D Tensor (Matrix):")
    print(tensor_2d)
    print()

    random_tensor = torch.rand(2, 3)
    print("Random Tensor (2x3):")
    print(random_tensor)
    print()

    zeros_tensor = torch.zeros(2, 3)
    print("Zeros Tensor (2x3):")
    print(zeros_tensor)
    print()

    ones_tensor = torch.ones(2, 3)
    print("Ones Tensor (2x3):")
    print(ones_tensor)
    ```

    output:

    ```
    1D Tensor (Vector):
    tensor([1, 2, 3])

    2D Tensor (Matrix):
    tensor([[1, 2],
            [3, 4]])

    Random Tensor (2x3):
    tensor([[0.9134, 0.1796, 0.5852],
            [0.8830, 0.9940, 0.2796]])

    Zeros Tensor (2x3):
    tensor([[0., 0., 0.],
            [0., 0., 0.]])

    Ones Tensor (2x3):
    tensor([[1., 1., 1.],
            [1., 1., 1.]])
    ```

* 将 tensor 从 numpy 转换到 torch

    * `torch.from_numpy()`

        这种方案会共享内存。

        ```py
        import torch
        import numpy as np

        # 创建 NumPy 数组
        numpy_array = np.array([1, 2, 3, 4, 5])

        # 转换为 Torch Tensor
        torch_tensor = torch.from_numpy(numpy_array)

        print("NumPy 数组:", numpy_array)
        print("Torch Tensor:", torch_tensor)
        print("Tensor 类型:", torch_tensor.dtype)
        ```

    * `torch.as_tensor()`

        这种方案会尽可能共享内存，但不保证。

        ```py
        torch_tensor = torch.as_tensor(numpy_array)
        ```

    * `torch.tensor()`

        这种方案会创建数据的副本。

        ```py
        torch_tensor = torch.tensor(numpy_array)
        ```

* tensor 的 indexing, slicing, reshaping 操作

    ```py
    import torch

    tensor = torch.tensor([[1, 2], [3, 4], [5, 6]])

    element = tensor[1, 0]
    print(f"Indexed Element (Row 1, Column 0): {element}")
    
    slice_tensor = tensor[:2, :]
    print(f"Sliced Tensor (First two rows): \n{slice_tensor}")

    reshaped_tensor = tensor.view(2, 3)
    print(f"Reshaped Tensor (2x3): \n{reshaped_tensor}")
    ```

    output:

    ```
    Indexed Element (Row 1, Column 0): 3
    Sliced Tensor (First two rows): 
    tensor([[1, 2],
            [3, 4]])
    Reshaped Tensor (2x3): 
    tensor([[1, 2, 3],
            [4, 5, 6]])
    ```