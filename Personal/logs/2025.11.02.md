* trap

    用于在脚本执行过程中捕获和处理信号或事件。它允许你在脚本接收到特定信号时执行指定的命令或函数，常用于清理临时文件、优雅退出或调试。

    syntax:

    ```bash
    trap [COMMAND] [SIGNALS]
    ```

    * `COMMAND`：捕获到信号后要执行的命令或函数（用引号包裹）。

    * `SIGNALS`：要捕获的信号名称或编号（如`INT`、`TERM`、`EXIT`等）。

    examples:

    * 捕获中断信号（如 Ctrl+C）

        ```bash
        trap "echo '脚本被中断！'; exit 1" INT
        ```

        当用户按下 Ctrl+C（发送 SIGINT 信号）时，脚本会打印消息并退出。

    * 脚本退出时清理资源

        ```bash
        trap "rm -f /tmp/tempfile; echo '清理完成'" EXIT
        ```

        无论脚本正常结束还是因错误退出，都会执行清理操作（删除临时文件）。

    * 忽略信号

        ```bash
        trap "" TERM
        ```

        忽略 SIGTERM 信号（常用于防止脚本被意外终止）。

    * 捕获调试信号

        ```bash
        trap "echo '调试模式：变量 x=$x'" DEBUG
        ```

        每次命令执行后打印变量 x 的值（用于调试）。

    * 重置信号处理

        ```bash
        trap - INT
        ```

        恢复对 SIGINT 的默认行为（移除之前的 trap 设置）。

    常用信号列表:

    | 信号名称 | 编号 | 触发条件 |
    | - | - | - |
    | INT | 2 | Ctrl+C 中断 |
    | TERM | 15 | 默认的 kill 命令 |
    | EXIT | 0 | 脚本退出时（非真实信号） |
    | ERR | - | 命令执行失败时（非真实信号） |
    | DEBUG | - | 每条命令执行后（非真实信号） |

    example:

    ```bash
    #!/bin/bash

    cleanup() {
        echo "正在清理临时文件..."
        rm -f /tmp/temp_*
    }

    trap cleanup EXIT    # 脚本退出时调用 cleanup
    trap "echo '忽略中断信号'" INT  # 捕获 Ctrl+C

    echo "创建临时文件..."
    touch /tmp/temp_1234

    echo "按 Ctrl+C 测试中断信号，或等待脚本完成..."
    sleep 5
    ```

    注意事项:

    * trap 的作用范围是当前的 Shell 环境。

    * 在函数中定义的 trap 会覆盖全局设置（除非显式声明为全局）。

* 在 transform 时，numpy 只能先 to tensor，再 resize，不能先 resize。PIL 图像既可以先 resize，也可以先 to tensor

    * numpy ndarray 只能先 to tensor;

        ```py
        from torchvision import transforms
        import numpy as np

        img = np.random.random((256, 256))

        trans = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((512, 512))
        ])

        img_trans = trans(img)

        print("img shape: {}".format(img.shape))
        print("img trans shape: {}".format(img_trans.shape))
        ```

        output:

        ```
        img shape: (256, 256)
        img trans shape: torch.Size([1, 512, 512])
        ```

        三维的数据也可以处理：

        `img = np.random.random((256, 256, 3))`

        output:

        ```
        img shape: (256, 256, 3)
        img trans shape: torch.Size([3, 512, 512])
        ```

        如果我们设置先 resize，那么会报错：

        ```py
        trans = transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor()
        ])
        ```

        output:

        ```
        ...
          File "/home/hlc/miniconda3/envs/torch/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py", line 31, in get_dimensions
            raise TypeError(f"Unexpected type {type(img)}")
        TypeError: Unexpected type <class 'numpy.ndarray'>
        ```

    * PIL 图片既可以先 resize，也可以先 to tensor:

        ```py
        from torchvision import transforms
        from PIL import Image

        img = Image.open('../example.jpg')

        trans = transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor()
        ])

        img_trans = trans(img)

        # print("img shape: {}".format(img.shape))  # PIL Image object has no shape attribute
        print("img trans shape: {}".format(img_trans.shape))
        ```

        output:

        ```
        img trans shape: torch.Size([3, 512, 512])
        ```

        先 to tensor 也是可以的：

        ```py
        trans = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((512, 512))
        ])
        ```

        output:

        ```
        img trans shape: torch.Size([3, 512, 512])
        ```

    如果先做了 to tensor，那么后续操作会在 GPU 里完成（是 CPU 吧？）。如果先做 resize，那么 resize 操作会调用 PIL 提供的 resize 函数。

* PyTorch Functional Transforms for Computer Vision

    Most of the functional transforms accept both PIL images and tensor images. A tensor image is a tensor with shape (C, H, W),

    if the input is a PIL image output is also a PIL image and the same for Tensor image.

    * `adjust_brightness()`

        adjusts the brightness of an image. It accepts both PIL image and Tensor Image.

        syntax:

        ```py
        torchvision.transforms.functional.adjust_brightness(
            img: Tensor,
            brightness_factor: float
        ) -> Tensor
        ```

        * img (Tensor): 输入图像，形状为 (..., H, W) 或 (C, H, W) 或 (H, W)

        * brightness_factor is any non-negative floating-point number:

            * brightness_factor = 1, the original image.

            * brightness_factor < 1, a darker output image.

            * brightness_factor > 1, a brighter output image.

        example:

        ```py
        import torchvision.transforms.functional as F
        import torch
        from PIL import Image

        image = Image.open('nature.jpg')

        output = F.adjust_brightness(image, brightness_factor=3.0)
        output.show()
        ```

        注意事项：

        * 亮度调整是通过将每个像素值乘以 brightness_factor 实现的

        * 结果会被裁剪到图像的原始值范围内（通常是 [0, 1]）

        * 如果输入是 PIL 图像，F.adjust_brightness() 的输出是 Tensor，而不是 PIL 图像。

        与``transforms.Compose`合用的例子：

        ```py
        transform = transforms.Compose([
            transforms.ToTensor(),  # PIL -> Tensor
            lambda x: F.adjust_brightness(x, brightness_factor=1.5),
            transforms.ToPILImage()  # Tensor -> PIL
        ])
        ```

* 科研对应的是网状学习

    难度：网状学习 > 非线性学习 > 线性学习

    或者说，网状学习就是非线性学习难度的极限。

    最简单的非线性学习是线性学习，最难的非线性学习是网状学习。

    对于网状学习，在起步时笔记是乱的，cache 是乱的，task 是乱的，实验也是乱的。因为不清楚要解决什么问题，看到实验现象也不清楚要问什么问题，各种任务的数量和方向都是指数级发散的，网状学习内部的概念又可能是不那么完全兼容的，可能有互相矛盾的地方。整个过程的主线更依赖直觉。

* `nn.Parameter()`

    nn.Parameter() 是一个用于将张量包装为模型参数的类，它是 torch.Tensor 的子类。

    syntax:

    ```py
    torch.nn.Parameter(data=None, requires_grad=True)
    ```

    params:

    * `data` (Tensor): 要包装为参数的张量

    * `requires_grad` (bool, 可选): 是否需要在反向传播中计算梯度，默认为 True