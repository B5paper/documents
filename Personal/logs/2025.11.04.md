* 难点不是实验证明/证伪了猜想，而是怎么想出来的这个实验？

* vscode 增加路径提示功能

    安装插件`Path Intellisense`，输入一半路径后，使用 Ctrl + Space 喚出路径自动补全。

* `NCCL_CUMEM_ENABLE`

    当 NCCL_CUMEM_ENABLE=1（或 =ON）时，NCCL 会尝试使用 CUDA 统一内存（UM） 来优化 GPU 之间的通信，减少显存拷贝开销，提升多 GPU 或跨节点通信性能。

    在某些硬件（如 NVLink 互连）下可能显著提升性能，但在 PCIe-only 环境下可能效果有限。

* CE memcpy

    CE Memcpy Support 指的是 Copy Engine（拷贝引擎） 对内存复制（Memcpy）操作的支持

    NVIDIA GPU 有专门的硬件引擎来处理数据拷贝任务，包括：

    * DMA（Direct Memory Access）引擎：负责主机（CPU）与设备（GPU）之间的数据传输。

    * CE（Copy Engine）：负责 GPU 内部或 GPU 之间的数据拷贝（如 cudaMemcpy、cudaMemcpyAsync）。

    CE 可以并行执行多个拷贝任务，提高数据传输效率。

* CUDA Event

    作用:

    CUDA Event 是 GPU 执行过程中的标记点，用于：

    * 测量 GPU 操作的时间间隔（性能分析）。

    * 同步 Stream 的执行（等待某个操作完成）。

    主要用途:

    * 性能计时（Profiling）：

        ```cpp
        cudaEvent_t event;
        cudaEventCreate(&event);

        kernelA<<<..., stream1>>>(...);
        cudaEventRecord(event, stream1);  // 在 stream1 中插入事件

        // stream2 等待 event 完成后再执行
        cudaStreamWaitEvent(stream2, event, 0);
        kernelB<<<..., stream2>>>(...);
        ```

    * 跨 Stream 同步：

        ```cpp
        cudaEvent_t event;
        cudaEventCreate(&event);

        kernelA<<<..., stream1>>>(...);
        cudaEventRecord(event, stream1);  // 在 stream1 中插入事件

        // stream2 等待 event 完成后再执行
        cudaStreamWaitEvent(stream2, event, 0);
        kernelB<<<..., stream2>>>(...);
        ```

    关键特点

    * 轻量级：Event 只是一个标记，不存储数据。

    * 可用于 Stream 间同步：cudaStreamWaitEvent 让一个 Stream 等待另一个 Stream 的某个 Event。

        example:

        ```cpp
        cudaStream_t stream1, stream2;
        cudaEvent_t event;

        cudaStreamCreate(&stream1);
        cudaStreamCreate(&stream2);
        cudaEventCreate(&event);

        // Stream1 执行 KernelA 并记录 Event
        kernelA<<<..., stream1>>>(...);
        cudaEventRecord(event, stream1);

        // Stream2 等待 Event 完成后再执行 KernelB
        cudaStreamWaitEvent(stream2, event, 0);
        kernelB<<<..., stream2>>>(...);

        // 清理
        cudaStreamDestroy(stream1);
        cudaStreamDestroy(stream2);
        cudaEventDestroy(event);
        ```

    * 查询完成状态：

        ```cpp
        if (cudaEventQuery(event) == cudaSuccess) {
            // 事件已完成
        }
        ```

* `os.walk()`

    递归地遍历指定目录及其所有子目录。

    syntax:

    ```py
    os.walk(top, topdown=True, onerror=None, followlinks=False)
    ```

    返回值

    生成一个三元组 (root, dirs, files)：

    * root: 当前正在遍历的目录路径

    * dirs: 当前目录下的子目录列表

    * files: 当前目录下的文件列表

    example:

    ```py
    import os

    # 基本遍历
    for root, dirs, files in os.walk('.'):
        print(f"当前目录: {root}")
        print(f"子目录: {dirs}")
        print(f"文件: {files}")
        print("-" * 50)
    ```

    参数说明

    * topdown=True: 从上往下遍历（先父目录后子目录）

    * topdown=False: 从下往上遍历（先子目录后父目录）

    * onerror: 错误处理函数

    * followlinks: 是否跟随符号链接

        默认不跟随符号链接，避免无限循环

* nn.Parameter()

    主要做两件事情：

    1. 为 tensor 增加 grad

    2. 将 tensor 注册到 model 的参数列表中

    example:

    * add grad

        ```py
        # 自动设置 requires_grad=True
        param = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]))
        print(param.requires_grad)  # 输出: True
        ```

    * register as model parameter

        ```py
        class MyModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.weight = nn.Parameter(torch.randn(10, 5))
                self.bias = nn.Parameter(torch.zeros(5))
            
            def forward(self, x):
                return x @ self.weight + self.bias

        model = MyModel()
        # 自动包含在模型参数中
        for name, param in model.named_parameters():
            print(f"{name}: {param.shape}")
        ```