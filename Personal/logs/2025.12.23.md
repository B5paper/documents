* 表征学习

    表征学习是机器学习的一个分支，其核心目标是自动发现数据中有效的特征表示（Representation），使原始数据转换为更容易被机器学习模型（如分类器、预测模型等）理解和使用的新形式。

    核心思想

    原始数据（如图像像素、文本字符、音频波形）通常具有高维度、稀疏、冗余或难以直接建模的特点。表征学习通过模型自动学习将这些原始数据转化为低维度、稠密、有意义的向量或编码（即“表征”），这些表征应当：

    * 保留重要信息（如语义、结构）。

    * 剔除噪声和冗余。

    * 有利于下游任务（如分类、检测、生成）。

    主要方法与类型

    * 监督表征学习

        * 通过有标签数据的监督任务（如图像分类）训练模型，其隐含层的输出可作为表征。

        * 例如：用预训练的ResNet提取图像特征向量。

    * 无监督表征学习

        * 仅利用无标签数据学习数据的内在结构。

        * 典型方法：

            * 自编码器（Autoencoder）：通过编码-解码重构学习紧凑表征。

            * 对比学习（Contrastive Learning）：如SimCLR、MoCo，通过拉近相似样本、推开不相似样本来学习表征。

            * 生成模型：如VAE、GAN，通过生成过程间接学习数据分布的表征。

    * 自监督学习（Self-supervised Learning）

        * 无监督学习的一种，通过设计“代理任务”自动生成标签来学习表征。

        * 例如：

            * 掩码语言模型（MLM）：如BERT，通过预测被遮盖的词语学习语言表征。

            * 图像拼图：通过预测图像块的相对位置学习视觉表征。

    * 迁移学习与预训练模型

        * 在大规模数据上预训练模型（如ImageNet、Wikipedia），将其学到的通用表征迁移到下游任务，通常只需微调。

    关键优势

    * 减少特征工程：自动学习特征，降低对人工设计特征的依赖。

    * 可迁移性：预训练的表征可泛化到多种任务。

    * 层次化抽象：深度模型能逐层学习从低级到高级的特征（如边缘→纹理→物体部件）。

    应用领域

    * 计算机视觉：图像特征提取、目标检测、人脸识别。

    * 自然语言处理：词向量（Word2Vec）、句向量（BERT、GPT）。

    * 语音处理：声学特征编码。

    * 推荐系统：用户与物品的嵌入表示。

    * 多模态学习：跨文本、图像、音频的统一表征。

    总结

    表征学习是将原始数据转化为“机器更懂”的形式的过程，是现代深度学习的基础。它通过数据驱动的方式自动发现内在规律，是实现通用人工智能的关键技术之一。随着大模型和多模态发展，学习通用、可解释、鲁棒的表征仍是核心挑战。

* 表征学习相关的论文和项目

    一、里程碑与经典论文

    1. 无监督/自监督学习（基石）

        * Word2Vec (2013) - Mikolov et al.

            * 标题：Efficient Estimation of Word Representations in Vector Space

            * 意义：开创性的词向量工作，提出CBOW和Skip-gram模型，表明可以从无标签文本中学习到语义丰富的词表征。

        * Autoencoder (2006重现热潮) - Hinton & Salakhutdinov

            * 标题：Reducing the Dimensionality of Data with Neural Networks

            * 意义：展示了深度自编码器能学习比PCA更好的数据低维表征，推动了深度表征学习。

        * BERT (2018) - Devlin et al.
 
            * 标题：BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

            * 意义：基于掩码语言模型的自监督预训练范式，彻底改变了NLP，证明了从纯文本中学习深度上下文表征的强大能力。

        * MoCo (2020) - He et al.

            * 标题：Momentum Contrast for Unsupervised Visual Representation Learning

            * 意义：视觉对比学习的经典之作，提出动量编码器和动态字典，使无监督视觉表征学习接近有监督性能。

        * SimCLR (2020) - Chen et al.
 
            * 标题：A Simple Framework for Contrastive Learning of Visual Representations

            * 意义：简化了视觉对比学习框架，强调了数据增强和投影头的重要性，影响深远。

    2. 理论分析与理解

        * InfoMax Principle (1985) - Linsker

            * 标题：Self-Organization in a Perceptual Network

            * 意义：提出最大化输入与输出之间互信息的原则，是很多自监督学习（如对比学习）的理论基础。

        + “On the Mutual Information Perspective...” (2020) - Tschannen et al.

            * 标题：On Mutual Information Maximization for Representation Learning

            * 意义：批判性地讨论了互信息最大化在实践中的挑战，推动了更务实的理解。

    二、前沿研究方向与论文

    1. 多模态表征学习

        * CLIP (2021) - Radford et al.

            * 标题：Learning Transferable Visual Models From Natural Language Supervision

            * 意义：通过图文对比学习，学习对齐的图像和文本表征，实现零样本分类，开启多模态研究新范式。

        * DALL-E / Stable Diffusion (2021-2022) - Ramesh et al. / Rombach et al.

            * 意义：基于扩散模型的文生图系统，其核心是学习一个能将文本和图像对齐到同一隐空间的强大多模态表征。

    2. 自监督学习新范式

        * MAE (2021) - He et al.

            * 标题：Masked Autoencoders Are Scalable Vision Learners

            * 意义：将BERT的掩码重建思想成功应用于计算机视觉，使用非对称编码器-解码器架构高效学习视觉表征。

        * BYOL (2020) - Grill et al.

            * 标题：Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning

            * 意义：无需负样本的对比学习，仅靠在线网络和目标网络的相互预测进行学习，挑战了对比学习的固有认知。

    3. 图表征学习

        * Node2Vec (2016) - Grover & Leskovec

            * 标题：node2vec: Scalable Feature Learning for Networks

            * 意义：将Word2Vec思想应用于图节点，通过有偏随机游走生成节点序列进行学习。

        * GraphSAGE (2017) - Hamilton et al.

            * 标题：Inductive Representation Learning on Large Graphs

            * 意义：提出一种归纳式框架，通过采样和聚合邻居特征来生成未见节点的表征。

        * Graph Contrastive Learning (2020+) - 如 GRACE, DGI

            * 意义：将对比学习思想应用于图数据，通过破坏图结构（如删边、加噪）来构建正负样本，学习鲁棒图表征。

    三、重要开源项目与工具库

    1. 综合项目/预训练模型库

        * Hugging Face Transformers

            * 链接: https://huggingface.co/docs/transformers

            * 介绍：最流行的NLP库，提供了数千个预训练的语言表征模型（BERT, GPT, T5等）及其微调、使用接口。是多模态和视觉模型也在迅速扩展。

        * PyTorch Image Models (timm)

            * 链接: https://github.com/rwightman/pytorch-image-models

            * 介绍：由Ross Wightman维护的计算机视觉模型库，包含大量有监督和自监督预训练的视觉骨干网络（如ViT, ResNet, ConvNeXt）及其代码。

        * OpenAI CLIP

            * 链接: https://github.com/openai/CLIP

            * 介绍：官方实现的CLIP模型，可以轻松提取图文对齐的特征，进行零样本预测。

        * FAIR’s Detectron2 & D2 Go

            * 链接: https://github.com/facebookresearch/detectron2

            * 介绍：Meta AI的视觉项目，不仅包含检测分割模型，也集成了很多先进的视觉自监督学习算法（如MoCo v2, DINO）。

    2. 自监督学习专项库

        * Lightly

            * 链接: https://github.com/lightly-ai/lightly

            * 介绍：专注于自监督学习的轻量级PyTorch库，提供了SimCLR, MoCo, BYOL, DINO等多种算法的简洁实现和数据流水线。

        * VISSL

            * 链接: https://github.com/facebookresearch/vissl

            * 介绍：Meta AI发布的视觉自监督学习库，整合了其大量研究（SwAV, SimCLR, MoCo等），适合进行大规模研究和复现。

        * DINO (Self-Distillation with no labels)

            * 链接: https://github.com/facebookresearch/dino

            * 介绍：Meta AI提出的无标签知识蒸馏方法，能学习到优异的视觉表征，并展现出突出的物体分割特性。

    3. 图表征学习库

        * PyTorch Geometric (PyG)

            * 链接: https://github.com/pyg-team/pytorch_geometric

            * 介绍：最流行的图神经网络库之一，实现了大量GNN模型（包括图自编码器、对比学习模型），是学习图表征的绝佳工具。

        * Deep Graph Library (DGL)

            * 链接: https://www.dgl.ai/

            * 介绍：另一个高效、易用的图神经网络库，支持多种后端，有丰富的模型示例和教程。

    学习建议路径

    * 入门：从 Word2Vec 和 Autoencoder 理解基本思想，然后深入 BERT 和 SimCLR/MoCo 理解现代自监督范式。

    * 实践：使用 Hugging Face 和 timm 库，加载预训练模型，在自己的数据上提取特征或进行微调。

    * 深入：选择一个方向（如多模态CLIP、图对比学习），研读最新论文，并用 Lightly、PyG 等库进行代码复现和实验。

    * 跟踪前沿：关注顶会（NeurIPS, ICLR, CVPR, ACL）中“Representation Learning”、“Self-Supervised Learning”、“Multi-modal”等主题的论文。

    希望这份列表能为你探索表征学习的广阔天地提供一个有力的起点！

* vim 中`}`命令

    移动到下一个空行的第一个非空白字符（段落移动）

    注意事项：

    * 配合 { 命令（向上跳转到上一个空行）使用

    * 计数前缀可用：3} 向下跳转3个段落

* vim `+`命令

    作用：移动到下一行的第一个非空白字符

    详细说明：

        相当于 j + ^ 的组合

        直接定位到下一行有文本内容的位置

        数字前缀可用：3+ 向下移动3行并定位

        反义命令是 -（移动到上一行的第一个非空白字符）

* vim `.`命令

    作用：重复上一次修改操作

    详细说明：

    * 重复最近一次在普通模式下执行的修改命令

    * 可以重复插入、删除、替换等操作

    * 示例：

        * dw 删除一个单词 → . 再删除下一个单词

        * ihello<Esc> 插入文本 → . 再次插入"hello"

* 上海血液科（川杨新苑附近）

    * 上海交通大学医学院附属仁济医院（东院）

        * 地址：浦东新区浦建路160号

        * 推荐理由：

            * 距离最近，交通最便利：这是距离川杨新苑最近的顶尖三甲医院之一。乘坐地铁7号线至“锦绣路”站，或13号线至“华鹏路”站，出站后步行即可到达，全程仅需约20-30分钟。

            * 实力雄厚：仁济医院是上海老牌综合性医院，其血液科是国家级重点临床专科，在白血病、淋巴瘤、多发性骨髓瘤等血液系统恶性疾病的诊断与治疗，以及造血干细胞移植方面处于国内领先水平。

            * 综合保障：作为大型综合医院，如需进行多学科会诊或处理并发症，院内资源丰富。

    * 上海市第一人民医院（南院）

        * 地址：松江区新松江路650号

        * 推荐理由：

            * 专科实力强：该院的血液科同样非常出色，是上海市医学重点学科，尤其在造血干细胞移植、出凝血疾病等方面特色显著。

            * 交通可达：从川杨新苑出发，可乘坐地铁13号线转9号线至“松江大学城”站，再换乘公交或出租车。虽然路程稍远（约1小时+），但考虑到其专科声誉，仍是重要选择。

    * 上海同济医院（同济大学附属同济医院）

        * 地址：普陀区新村路389号

        * 推荐理由：

            * 血液科为优势学科：该院血液科是同济大学重点学科，在各类贫血、血小板减少症及血液肿瘤的诊治方面经验丰富。

            * 地铁直达：从川杨新苑乘坐13号线可直达“同济医院”站（约50分钟），出站即达，对于复诊患者非常方便。

* git submodule 常用命令

    状态检查：git submodule status

    初始化：git submodule init

    更新所有：git submodule update --init --recursive

    删除子模块：

        git submodule deinit -f libs/mylib

        rm -rf .git/modules/libs/mylib

        git rm -f libs/mylib

    注意事项

    * 版本固定：父仓库记录的是子模块的提交哈希，不是分支

    * 递归子模块：使用 --recursive 选项处理嵌套子模块

    * 工作流程：在子模块目录中的修改需要单独提交和推送

    * 团队协作：所有成员都需要初始化子模块

    * 分离头指针：子模块总是检出特定提交，不在任何分支上

    * 双重配置：.gitmodules（共享）和 .git/config（本地）

    * 独立仓库：每个子模块都是完整的Git仓库

    子模块适用于将第三方库或共享组件作为依赖管理，但复杂度较高，对于简单依赖可考虑 Git subtree 或包管理器。

* git submodule 缩写

    ```bash
    # 等价于 init + update
    git submodule update --init

    # 递归初始化并更新所有子模块
    git submodule update --init --recursive

    # 克隆时直接初始化并更新
    git clone --recurse-submodules <repo-url>
    ```

* git submodule 实测

    * 在仓库 A 中`git submodule add <sub-repo-B> <dst-dir>`时，会自动创建`<dst-dir>`目录，并拉取`<sub-repo-B>`的代码

        此时 A 中`.git/config`会发生改变，添加 submodule 相关信息。

    * A 中添加完 submodule 后，执行提交时，只会提交 A 中：

        1. 新文件`.gitmodules`

        2. 新建的空目录`<dst-dir>`

    * 将 A clone 到 C 时，C 中会有：

        1. 文件`.submodule`

        2. 空目录`<dst-dir>`

        注意，此时 C 的`.git/config`中并没有 submodule 相关的信息。

    * 在 C 中执行`git submodule init`后，`.gitmodules`中的数据会被写入到`.git/config`中

    * 在 C 中执行`git submodule update`后，会正式开始拉取 B 的内容，并 checkout 到指定的 commit

        注意：
        
        * 此时 B 是 head detected 状态

        * repo C 中，submodule B 的 commit 会被暂时锁定在 A add B 时的那个 commit
        
            就算此时 repo B 进行了提交，在 C 中执行`git submodule update`或重新 clone C 也不会改变 B 的 commit。

        * 只有 repo A 改变了 submodule B 的 commit，在 C 中执行`git submodule update`才会同步更新 B 的 commit

        * 如果 C 想脱离 A 的控制，独立更新 B 的 commit，需要进入`<sub-B-dir>`中执行`git pull`。

* git submodule status

    你会看到类似：

    ```
     e3a1c9b8c9f2e6f4a8d9c2e3b9f5a1d2c3e4f5 repo_B (heads/main)
    ```

    如果前面是空格（不是`-`），说明子模块已 checkout 成功。

* QQQ 和 SPY 是美股市场中最知名、交易量最大的两只指数型交易基金

    SPY

        全称/代码：SPDR S&P 500 ETF Trust，代码 SPY。

        追踪指数：标普500指数。

        代表什么：代表了美国整体股市的大盘表现。它包含美国500家市值最大、流动性最强的上市公司，覆盖各个行业（金融、科技、医疗、消费、工业等）。

        特点：

            市场基准：通常被认为是美国股票市场的“晴雨表”。

            行业分散：投资非常多元化，不依赖于单一行业。

            偏向传统经济：虽然包含科技巨头，但金融、医疗、消费等传统行业占比也很大。

        适合的投资者：希望长期投资美国整体经济、追求市场平均回报、偏好稳定和分散风险的投资者。

    QQQ

        全称/代码：Invesco QQQ Trust，代码 QQQ。

        追踪指数：纳斯达克100指数。

        代表什么：代表了美国科技成长股和非金融行业的领军企业。它包含在纳斯达克交易所上市的100家最大的非金融公司。

        特点：

            高度集中科技：超过50%的权重集中在信息技术板块，此外还包括通信服务（如谷歌、Meta）、可选消费（如特斯拉、亚马逊）和生物科技。

            成长性强：成分股大多是具有高增长潜力的科技、互联网和生物技术公司。

            波动性较大：由于集中在高增长的科技板块，其股价的波动性通常比SPY更高。

        适合的投资者：看好科技和创新行业长期发展、能承受较高波动以追求更高增长潜力的投资者。

    核心区别对比表
    特性	SPY	QQQ
    追踪指数	标普500指数	纳斯达克100指数
    核心定位	美国大盘股市场整体	科技成长股龙头
    行业分布	非常分散（科技约30%，金融、医疗、消费等占比高）	极度集中（科技+通信服务+可选消费占绝大比例）
    前五大持仓	苹果、微软、英伟达、亚马逊、Meta	苹果、微软、英伟达、亚马逊、Meta
    风险与波动	相对较低，更稳定	相对较高，波动更大
    股息率	通常高于QQQ	通常较低（成长股更倾向于回购股票而非分红）

    重要提示

    * 并非直接投资美股唯一选择：SPY和QQQ是ETF（交易所交易基金）中的元老，但并非唯一选择。例如，追踪标普500的ETF还有VOO、IVV，它们的管理费率（0.03%）比SPY（0.0945%）更低。追踪纳斯达克100的也有QLD等。

    * 交易属性：两者都像股票一样在交易所实时交易，流动性极佳。

    * 投资决策：选择哪一个取决于您的投资目标、风险承受能力和对行业的看法。

        * 如果想获得美国经济的平均增长，选SPY或其替代品（如VOO）。

        * 如果特别看好科技和创新的未来，并愿意承担相应波动，选QQQ。

        * 很多投资者也会在投资组合中同时配置两者，以平衡风险与增长。

    总结：SPY 是美国股市的“全能选手”，而 QQQ 是押注科技未来的“明星队”。了解其区别有助于您做出更符合自身情况的投资决策。

