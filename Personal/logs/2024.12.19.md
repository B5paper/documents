* contrastive prn. [kənˈtræstɪv] adj. 对比的

* 一个 block (thread block) 中的 threads 数量是有限的，因为每个 block 会被绑定到一个 sm (streaming multiprocessor) 上，这个 block 中的所有 thread 都会在这个 sm 上执行。

    > On current GPUs, a thread block may contain up to 1024 threads.

    当前的 gpu，每个 block 最多有 1024 个 thread。

* block 也可以被组织为一／二／三维的 grid。这么做主要为了适配需要计算的数据。通常数据的 dim length 是会超过 gpu 中流处理器的数量的

    example:

    `main_3.cu`:

    ```cpp
    __global__ void vec_add_blk(float *A, float *B)
    {
        int x = blockIdx.x * blockDim.x + threadIdx.x;
        A[x] = A[x] + B[x];
        printf("%d, %d, %d\n", blockDim.x, blockDim.y, blockDim.z);
    }

    int main()
    {
        float *cubuf_A, *cubuf_B;
        cudaMalloc(&cubuf_A, 8 * sizeof(float));
        cudaMalloc(&cubuf_B, 8 * sizeof(float));
        float *buf_A, *buf_B;
        buf_A = (float*) malloc(8 * sizeof(float));
        buf_B = (float*) malloc(8 * sizeof(float));
        for (int i = 0; i < 8; ++i)
        {
            buf_A[i] = rand() % 5;
            buf_B[i] = rand() % 5;
        }

        printf("buf A:\n");
        for (int i = 0; i < 8; ++i)
            printf("%.2f, ", buf_A[i]);
        putchar('\n');

        printf("buf B:\n");
        for (int i = 0; i < 8; ++i)
            printf("%.2f, ", buf_B[i]);
        putchar('\n');

        cudaMemcpy(cubuf_A, buf_A, 8 * sizeof(float), cudaMemcpyHostToDevice);
        cudaMemcpy(cubuf_B, buf_B, 8 * sizeof(float), cudaMemcpyHostToDevice);
        // vec_add<<<1, 8>>>(cubuf_A, cubuf_B);
        vec_add_blk<<<4, 2>>>(cubuf_A, cubuf_B);
        cudaMemcpy(buf_A, cubuf_A, 8 * sizeof(float), cudaMemcpyDeviceToHost);
        
        printf("buf A:\n");
        for (int i = 0; i < 8; ++i)
            printf("%.2f, ", buf_A[i]);
        putchar('\n');

        return 0;
    }
    ```

    output:

    ```
    buf A:
    3.00, 2.00, 3.00, 1.00, 4.00, 2.00, 0.00, 3.00, 
    buf B:
    1.00, 0.00, 0.00, 2.00, 1.00, 2.00, 4.00, 1.00, 
    2, 1, 1
    2, 1, 1
    2, 1, 1
    2, 1, 1
    2, 1, 1
    2, 1, 1
    2, 1, 1
    2, 1, 1
    buf A:
    4.00, 2.00, 3.00, 3.00, 5.00, 4.00, 4.00, 4.00,
    ```

    可以看到`blockDim`其实就是每个维度的 length。

    grid 有点像 batch 的概念，比如一个 shape 为`(20, 8, 4)`的数据，我既可以一次性处理，也可以拆分成 4 个`(5, 2, 1)`进行处理。前者的 grid 即为 1，后者的 grid 即为`(4, 4, 4)`。

    如果拆成 grid 进行处理，那么在确定数组索引时，就需要用`int x = blockIdx.x * blockDim.x + threadIdx.x;`这种方式。

    grid 与 grid 之间并不保证是并行执行的，可能是并行，也可能是串行。

    > Thread blocks are required to execute independently: It must be possible to execute them in any order, in parallel or in series.