* [v] qa: 4 units

    正确率：3 / 4

    feedback:

    1. 必须先执行`glfwInit()`，等`glfwMakeContextCurrent()`执行后，再执行`glewInit()`，

        没有`glewInit()`，`glCreateShader()`会立即返回失败。

    2. 调研 exam 时显示 unit 的 id 和 idx

* [v] qa: review

* [v] reorg: documents 30 mins

* [v] 调研 nccl 中调用 cuda api 申请的显存的 va，与 load/store 相关的 va，是否为同一个 va？

    feedback:

    1. 猜想：nccl 的底层通信可以走 host 中转，也可以走 pcie p2p，无论走哪种方式，一定是 launch kernel 去处理的通信，launch kernel 一定会直接处理 va。因此如果是 p2p 通信，那么这里的 va 就是 peer device bar 空间的 va；如果是走 host 中转，那么这里的 va 就是 host memory 的 va，此时 host memory 作为 buffer。

    2. nccl 中的 src 一直都是`0xfe`，`0x7ffe60c00000`，且每次都是相同的，可能和 cudaMalloc 还不太一样。